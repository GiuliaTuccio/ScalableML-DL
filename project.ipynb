{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiuliaTuccio/ScalableML-DL/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4H0PcelCQi7"
      },
      "source": [
        "**Final Project**\n",
        "\n",
        "\n",
        "In this project we build a reccomandation system for music based on the notion of spectogram; a picture created starting by an mp3 file, and representing the frequences with respect to time.\n",
        "\n",
        "The mp3 file are downloaded on the page https://github.com/mdeff/fma, containing 8000 songs, belonging to one of the 8 following genres:\n",
        "1. Hip-Hop\n",
        "2. International\n",
        "3. Electronic\n",
        "4. Folk\n",
        "5. Experimental\n",
        "6. Rock\n",
        "7. Pop\n",
        "8. Instrumental\n",
        "\n",
        "As soon as the spectograms are generated, we proceed into cutting the images into the desired shape (128x128) and converting them into greyscale.\n",
        "\n",
        "Successively, we build the classification network and proceed with the training.\n",
        "\n",
        "Finnally, we discerd the last layer (producing the classification of the songs), keeping the dense layer made by 32-features vector.\n",
        "The features will be used to compute the reccomondation system based on the cosine similarity, between a song inputed by the user and the 'Test' set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRzGZd3cCNBI"
      },
      "source": [
        "Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw3645AOMA_1",
        "outputId": "758d7159-c769-4d4c-bb85-f12708968897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from PIL import Image\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image \n",
        "from keras.models import Sequential\n",
        "from keras import initializers\n",
        "from keras import optimizers\n",
        "from keras.layers import *\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "import cv2\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1nxEPnG73ZVp"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltTazIWECTia"
      },
      "source": [
        "Importing Google Drive, where the songs are saved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApI8bA5dMdDw",
        "outputId": "d624b486-12e9-49a5-c8bf-8c4c2926c3f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2ILDPdpCiUn"
      },
      "source": [
        "Uploading the excel file containing the information about the songs.\n",
        "\n",
        "The first column contains the id, whereas the 41st column defines the genre of the song"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf0rf07mrSSL",
        "outputId": "16c1a1d1-80c7-47d3-e663-423b4af73df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rock                   14182\n",
            "Experimental           10608\n",
            "Electronic              9372\n",
            "Hip-Hop                 3552\n",
            "Folk                    2803\n",
            "Pop                     2332\n",
            "Instrumental            2079\n",
            "International           1389\n",
            "Classical               1230\n",
            "Jazz                     571\n",
            "Old-Time / Historic      554\n",
            "Spoken                   423\n",
            "Country                  194\n",
            "Soul-RnB                 175\n",
            "Blues                    110\n",
            "Easy Listening            24\n",
            "Name: Unnamed: 40, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Upload the data set containing the informations about the songs\n",
        "\n",
        "filename_metadata = \"/content/gdrive/MyDrive/tracks.csv\"\n",
        "tracks = pd.read_csv(filename_metadata, header=2)\n",
        "\n",
        "print(tracks['Unnamed: 40'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Pg56rgk24V1d"
      },
      "outputs": [],
      "source": [
        "tracks_array = tracks.values\n",
        "\n",
        "# extract the information\n",
        "tracks_id_array = tracks_array[: , 0]\n",
        "tracks_genre_array = tracks_array[: , 40]\n",
        "\n",
        "# save the id and the genre in an array\n",
        "tracks_id_array = tracks_id_array.reshape(tracks_id_array.shape[0], 1)\n",
        "\n",
        "tracks_genre_array = tracks_genre_array.reshape(tracks_genre_array.shape[0], 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "004V_hmeDJdN"
      },
      "source": [
        "The following code is a trial for one folder.\n",
        "\n",
        "Firstly, a directory cointaining the spectogram images is created.\n",
        "\n",
        "Then, a loop goes through each of the mp3 files, saves the index and the genre, and uses the library librosa to generate the spectogram.\n",
        "\n",
        "The spectogram is then converted in decibel units (melspectogram) and saved as a jpg image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ0oApor37eX"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('/content/gdrive/MyDrive/Train_Spectogram_Images_000'):\n",
        "            os.makedirs('/content/gdrive/MyDrive/Train_Spectogram_Images_000')\n",
        "\n",
        "folder_sample = '/content/gdrive/MyDrive/music-data/000'\n",
        "            \n",
        "\n",
        "file_names = [os.path.join(folder_sample, f)\n",
        "                  for f in os.listdir(folder_sample)\n",
        "                  if f.endswith(\".mp3\")]\n",
        "\n",
        "count = 0\n",
        "           \n",
        "for f in file_names:\n",
        "    #track_id = int(re.search('/content/gdrive/MyDrive/music-data/.*/(.+?).mp3', f).group(1))\n",
        "    track_id = int(re.search('/content/gdrive/MyDrive/music-data/000/(.+?).mp3', f).group(1))\n",
        "    print(track_id)\n",
        "    idx = list(tracks_id_array).index(track_id)\n",
        "    if(str(tracks_genre_array[idx, 0]) != '0'):\n",
        "      print(f)\n",
        "    # returns audio time series and sampling rate\n",
        "    y, sr =  librosa.load(f)\n",
        "    # Display of mel-frequency spectrogram coefficients\n",
        "    melspectrogram_array = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
        "    # Convert a power spectrogram (amplitude squared) to decibel (dB) units\n",
        "    mel = librosa.power_to_db(melspectrogram_array)\n",
        "    # Save the images of the spectogram\n",
        "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "    fig_size[0] = float(mel.shape[1]) / float(100)\n",
        "    fig_size[1] = float(mel.shape[0]) / float(100)\n",
        "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
        "    plt.axis('off')\n",
        "    plt.axes([0., 0., 1., 1.0], frameon=False, xticks=[], yticks=[])\n",
        "    librosa.display.specshow(mel, cmap='gray_r')\n",
        "    plt.savefig(\"/content/gdrive/MyDrive/Train_Spectogram_Images_000/\"+str(count)+\"_\"+str(tracks_genre_array[idx,0])+\".jpg\", bbox_inches=None, pad_inches=0)\n",
        "    plt.close()\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31C1eiAHD2OS"
      },
      "source": [
        "Here the same procedure is replicated for all the mp3 files in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqBzVxiISnnZ"
      },
      "outputs": [],
      "source": [
        "# count = 0\n",
        "# if not os.path.exists('/content/Train_Spectogram_Images'):\n",
        "#             os.makedirs('/content/Train_Spectogram_Images')\n",
        "\n",
        "# folder_sample = '/content/gdrive/MyDrive/music-data'\n",
        "# directories = [d for d in os.listdir(folder_sample)\n",
        "#                  if os.path.isdir(os.path.join(folder_sample, d))]\n",
        "              \n",
        "# for d in directories:\n",
        "#     label_directory = os.path.join(folder_sample, d)\n",
        "#     file_names = [os.path.join(label_directory, f)\n",
        "#                   for f in os.listdir(label_directory)\n",
        "#                   if f.endswith(\".mp3\")]\n",
        "            \n",
        "#     for f in file_names:\n",
        "#         print(file_names)\n",
        "#         track_id = int(re.search('/content/gdrive/MyDrive/music-data/000/(.+?).mp3', f).group(1))\n",
        "#         print(track_id)\n",
        "#         #print(track_id)\n",
        "#         idx = list(tracks_id_array).index(track_id)\n",
        "#         # returns audio time series and sampling rate\n",
        "#         y, sr =  librosa.load(f)\n",
        "#         # Display of mel-frequency spectrogram coefficients\n",
        "#         melspectrogram_array = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
        "#         # Convert a power spectrogram (amplitude squared) to decibel (dB) units\n",
        "#         mel = librosa.power_to_db(melspectrogram_array)\n",
        "#         # Save the images of the spectogram\n",
        "#         fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "#         fig_size[0] = float(mel.shape[1]) / float(100)\n",
        "#         fig_size[1] = float(mel.shape[0]) / float(100)\n",
        "#         plt.rcParams[\"figure.figsize\"] = fig_size\n",
        "#         plt.axis('off')\n",
        "#         plt.axes([0., 0., 1., 1.0], frameon=False, xticks=[], yticks=[])\n",
        "#         librosa.display.specshow(mel, cmap='gray_r')\n",
        "#         plt.savefig(\"'/content/Train_Spectogram_Images'\"+str(count)+\"-\"+str(tracks_genre_array[idx,0])+\".jpg\", bbox_inches=None, pad_inches=0)\n",
        "#         plt.close()\n",
        "#         count += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDhxVF-xEAr1"
      },
      "source": [
        "The spectograms created are then converted into a picture of the desired dimensions. \n",
        "\n",
        "This means that all the images are cropped. The genre is saved as the name of the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjBc6Fxothtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aa7e8ea-1671-4bcf-c81b-37d0eb4c20ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "44792\n",
            "44793\n",
            "44794\n",
            "44795\n",
            "44796\n",
            "44797\n",
            "44798\n",
            "44799\n",
            "44800\n",
            "44801\n",
            "44802\n",
            "44803\n",
            "44804\n",
            "44805\n",
            "44806\n",
            "44807\n",
            "44808\n",
            "44809\n",
            "44810\n",
            "44811\n",
            "44812\n",
            "44813\n",
            "44814\n",
            "44815\n",
            "44816\n",
            "44817\n",
            "44818\n",
            "44819\n",
            "44820\n",
            "44821\n",
            "44822\n",
            "44823\n",
            "44824\n",
            "44825\n",
            "44826\n",
            "44827\n",
            "44828\n",
            "44829\n",
            "44830\n",
            "44831\n",
            "44832\n",
            "44833\n",
            "44834\n",
            "44835\n",
            "44836\n",
            "44837\n",
            "44838\n",
            "44839\n",
            "44840\n",
            "44841\n",
            "44842\n",
            "44843\n",
            "44844\n",
            "44845\n",
            "44846\n",
            "44847\n",
            "44848\n",
            "44849\n",
            "44850\n",
            "44851\n",
            "44852\n",
            "44853\n",
            "44854\n",
            "44855\n",
            "44856\n",
            "44857\n",
            "44858\n",
            "44859\n",
            "44860\n",
            "44861\n",
            "44862\n",
            "44863\n",
            "44864\n",
            "44865\n",
            "44866\n",
            "44867\n",
            "44868\n",
            "44869\n",
            "44870\n",
            "44871\n",
            "44872\n",
            "44873\n",
            "44874\n",
            "44875\n",
            "44876\n",
            "44877\n",
            "44878\n",
            "44879\n",
            "44880\n",
            "44881\n",
            "44882\n",
            "44883\n",
            "44884\n",
            "44885\n",
            "44886\n",
            "44887\n",
            "44888\n",
            "44889\n",
            "44890\n",
            "44891\n",
            "44892\n",
            "44893\n",
            "44894\n",
            "44895\n",
            "44896\n",
            "44897\n",
            "44898\n",
            "44899\n",
            "44900\n",
            "44901\n",
            "44902\n",
            "44903\n",
            "44904\n",
            "44905\n",
            "44906\n",
            "44907\n",
            "44908\n",
            "44909\n",
            "44910\n",
            "44911\n",
            "44912\n",
            "44913\n",
            "44914\n",
            "44915\n",
            "44916\n",
            "44917\n",
            "44918\n",
            "44919\n",
            "44920\n",
            "44921\n",
            "44922\n",
            "44923\n",
            "44924\n",
            "44925\n",
            "44926\n",
            "44927\n",
            "44928\n",
            "44929\n",
            "44930\n",
            "44931\n",
            "44932\n",
            "44933\n",
            "44934\n",
            "44935\n",
            "44936\n",
            "44937\n",
            "44938\n",
            "44939\n",
            "44940\n",
            "44941\n",
            "44942\n",
            "44943\n",
            "44944\n",
            "44945\n",
            "44946\n",
            "44947\n",
            "44948\n",
            "44949\n",
            "44950\n",
            "44951\n",
            "44952\n",
            "44953\n",
            "44954\n",
            "44955\n",
            "44956\n",
            "44957\n",
            "44958\n",
            "44959\n",
            "44960\n",
            "44961\n",
            "44962\n",
            "44963\n",
            "44964\n",
            "44965\n",
            "44966\n",
            "44967\n",
            "44968\n",
            "44969\n",
            "44970\n",
            "44971\n",
            "44972\n",
            "44973\n",
            "44974\n",
            "44975\n",
            "44976\n",
            "44977\n",
            "44978\n",
            "44979\n",
            "44980\n",
            "44981\n",
            "44982\n",
            "44983\n",
            "44984\n",
            "44985\n",
            "44986\n",
            "44987\n",
            "44988\n",
            "44989\n",
            "44990\n",
            "44991\n",
            "44992\n",
            "44993\n",
            "44994\n",
            "44995\n",
            "44996\n",
            "44997\n",
            "44998\n",
            "44999\n",
            "45000\n",
            "45001\n",
            "45002\n",
            "45003\n",
            "45004\n",
            "45005\n",
            "45006\n",
            "45007\n",
            "45008\n",
            "45009\n",
            "45010\n",
            "45011\n",
            "45012\n",
            "45013\n",
            "45014\n",
            "45015\n",
            "45016\n",
            "45017\n",
            "45018\n",
            "45019\n",
            "45020\n",
            "45021\n",
            "45022\n",
            "45023\n",
            "45024\n",
            "45025\n",
            "45026\n",
            "45027\n",
            "45028\n",
            "45029\n",
            "45030\n",
            "45031\n",
            "45032\n",
            "45033\n",
            "45034\n",
            "45035\n",
            "45036\n",
            "45037\n",
            "45038\n",
            "45039\n",
            "45040\n",
            "45041\n",
            "45042\n",
            "45043\n",
            "45044\n",
            "45045\n",
            "45046\n",
            "45047\n",
            "45048\n",
            "45049\n",
            "45050\n",
            "45051\n",
            "45052\n",
            "45053\n",
            "45054\n",
            "45055\n",
            "45056\n",
            "45057\n",
            "45058\n",
            "45059\n",
            "45060\n",
            "45061\n",
            "45062\n",
            "45063\n",
            "45064\n",
            "45065\n",
            "45066\n",
            "45067\n",
            "45068\n",
            "45069\n",
            "45070\n",
            "45071\n",
            "45072\n",
            "45073\n",
            "45074\n",
            "45075\n",
            "45076\n",
            "45077\n",
            "45078\n",
            "45079\n",
            "45080\n",
            "45081\n",
            "45082\n",
            "45083\n",
            "45084\n",
            "45085\n",
            "45086\n",
            "45087\n",
            "45088\n",
            "45089\n",
            "45090\n",
            "45091\n",
            "45092\n",
            "45093\n",
            "45094\n",
            "45095\n",
            "45096\n",
            "45097\n",
            "45098\n",
            "45099\n",
            "45100\n",
            "45101\n",
            "45102\n",
            "45103\n",
            "45104\n",
            "45105\n",
            "45106\n",
            "45107\n",
            "45108\n",
            "45109\n",
            "45110\n",
            "45111\n",
            "45112\n",
            "45113\n",
            "45114\n",
            "45115\n",
            "45116\n",
            "45117\n",
            "45118\n",
            "45119\n",
            "45120\n",
            "45121\n",
            "45122\n",
            "45123\n",
            "45124\n",
            "45125\n",
            "45126\n",
            "45127\n",
            "45128\n",
            "45129\n",
            "45130\n",
            "45131\n",
            "45132\n",
            "45133\n",
            "45134\n",
            "45135\n",
            "45136\n",
            "45137\n",
            "45138\n",
            "45139\n",
            "45140\n",
            "45141\n",
            "45142\n",
            "45143\n",
            "45144\n",
            "45145\n",
            "45146\n",
            "45147\n",
            "45148\n",
            "45149\n",
            "45150\n",
            "45151\n",
            "45152\n",
            "45153\n",
            "45154\n",
            "45155\n",
            "45156\n",
            "45157\n",
            "45158\n",
            "45159\n",
            "45160\n",
            "45161\n",
            "45162\n",
            "45163\n",
            "45164\n",
            "45165\n",
            "45166\n",
            "45167\n",
            "45168\n",
            "45169\n",
            "45170\n",
            "45171\n",
            "45172\n",
            "45173\n",
            "45174\n",
            "45175\n",
            "45176\n",
            "45177\n",
            "45178\n",
            "45179\n",
            "45180\n",
            "45181\n",
            "45182\n",
            "45183\n",
            "45184\n",
            "45185\n",
            "45186\n",
            "45187\n",
            "45188\n",
            "45189\n",
            "45190\n",
            "45191\n",
            "45192\n",
            "45193\n",
            "45194\n",
            "45195\n",
            "45196\n",
            "45197\n",
            "45198\n",
            "45199\n",
            "45200\n",
            "45201\n",
            "45202\n",
            "45203\n",
            "45204\n",
            "45205\n",
            "45206\n",
            "45207\n",
            "45208\n",
            "45209\n",
            "45210\n",
            "45211\n",
            "45212\n",
            "45213\n",
            "45214\n",
            "45215\n",
            "45216\n",
            "45217\n",
            "45218\n",
            "45219\n",
            "45220\n",
            "45221\n",
            "45222\n",
            "45223\n",
            "45224\n",
            "45225\n",
            "45226\n",
            "45227\n",
            "45228\n",
            "45229\n",
            "45230\n",
            "45231\n",
            "45232\n",
            "45233\n",
            "45234\n",
            "45235\n",
            "45236\n",
            "45237\n",
            "45238\n",
            "45239\n",
            "45240\n",
            "45241\n",
            "45242\n",
            "45243\n",
            "45244\n",
            "45245\n",
            "45246\n",
            "45247\n",
            "45248\n",
            "45249\n",
            "45250\n",
            "45251\n",
            "45252\n",
            "45253\n",
            "45254\n",
            "45255\n",
            "45256\n",
            "45257\n",
            "45258\n",
            "45259\n",
            "45260\n",
            "45261\n",
            "45262\n",
            "45263\n",
            "45264\n",
            "45265\n",
            "45266\n",
            "45267\n",
            "45268\n",
            "45269\n",
            "45270\n",
            "45271\n",
            "45272\n",
            "45273\n",
            "45274\n",
            "45275\n",
            "45276\n",
            "45277\n",
            "45278\n",
            "45279\n",
            "45280\n",
            "45281\n",
            "45282\n",
            "45283\n",
            "45284\n",
            "45285\n",
            "45286\n",
            "45287\n",
            "45288\n",
            "45289\n",
            "45290\n",
            "45291\n",
            "45292\n",
            "45293\n",
            "45294\n",
            "45295\n",
            "45296\n",
            "45297\n",
            "45298\n",
            "45299\n",
            "45300\n",
            "45301\n",
            "45302\n",
            "45303\n",
            "45304\n",
            "45305\n",
            "45306\n",
            "45307\n",
            "45308\n",
            "45309\n",
            "45310\n",
            "45311\n",
            "45312\n",
            "45313\n",
            "45314\n",
            "45315\n",
            "45316\n",
            "45317\n",
            "45318\n",
            "45319\n",
            "45320\n",
            "45321\n",
            "45322\n",
            "45323\n",
            "45324\n",
            "45325\n",
            "45326\n",
            "45327\n",
            "45328\n",
            "45329\n",
            "45330\n",
            "45331\n",
            "45332\n",
            "45333\n",
            "45334\n",
            "45335\n",
            "45336\n",
            "45337\n",
            "45338\n",
            "45339\n",
            "45340\n",
            "45341\n",
            "45342\n",
            "45343\n",
            "45344\n",
            "45345\n",
            "45346\n",
            "45347\n",
            "45348\n",
            "45349\n",
            "45350\n",
            "45351\n",
            "45352\n",
            "45353\n",
            "45354\n",
            "45355\n",
            "45356\n",
            "45357\n",
            "45358\n",
            "45359\n",
            "45360\n",
            "45361\n",
            "45362\n",
            "45363\n",
            "45364\n",
            "45365\n",
            "45366\n",
            "45367\n",
            "45368\n",
            "45369\n",
            "45370\n",
            "45371\n",
            "45372\n",
            "45373\n",
            "45374\n",
            "45375\n",
            "45376\n",
            "45377\n",
            "45378\n",
            "45379\n",
            "45380\n",
            "45381\n",
            "45382\n",
            "45383\n",
            "45384\n",
            "45385\n",
            "45386\n",
            "45387\n",
            "45388\n",
            "45389\n",
            "45390\n",
            "45391\n",
            "45392\n",
            "45393\n",
            "45394\n",
            "45395\n",
            "45396\n",
            "45397\n",
            "45398\n",
            "45399\n",
            "45400\n",
            "45401\n",
            "45402\n",
            "45403\n",
            "45404\n",
            "45405\n",
            "45406\n",
            "45407\n",
            "45408\n",
            "45409\n",
            "45410\n",
            "45411\n",
            "45412\n",
            "45413\n",
            "45414\n",
            "45415\n",
            "45416\n",
            "45417\n",
            "45418\n",
            "45419\n",
            "45420\n",
            "45421\n",
            "45422\n",
            "45423\n",
            "45424\n",
            "45425\n",
            "45426\n",
            "45427\n",
            "45428\n",
            "45429\n",
            "45430\n",
            "45431\n",
            "45432\n",
            "45433\n",
            "45434\n",
            "45435\n",
            "45436\n",
            "45437\n",
            "45438\n",
            "45439\n",
            "45440\n",
            "45441\n",
            "45442\n",
            "45443\n",
            "45444\n",
            "45445\n",
            "45446\n",
            "45447\n",
            "45448\n",
            "45449\n",
            "45450\n",
            "45451\n",
            "45452\n",
            "45453\n",
            "45454\n",
            "45455\n",
            "45456\n",
            "45457\n",
            "45458\n",
            "45459\n",
            "45460\n",
            "45461\n",
            "45462\n",
            "45463\n",
            "45464\n",
            "45465\n",
            "45466\n",
            "45467\n",
            "45468\n",
            "45469\n",
            "45470\n",
            "45471\n",
            "45472\n",
            "45473\n",
            "45474\n",
            "45475\n",
            "45476\n",
            "45477\n",
            "45478\n",
            "45479\n",
            "45480\n",
            "45481\n",
            "45482\n",
            "45483\n",
            "45484\n",
            "45485\n",
            "45486\n",
            "45487\n",
            "45488\n",
            "45489\n",
            "45490\n",
            "45491\n",
            "45492\n",
            "45493\n",
            "45494\n",
            "45495\n",
            "45496\n",
            "45497\n",
            "45498\n",
            "45499\n",
            "45500\n",
            "45501\n",
            "45502\n",
            "45503\n",
            "45504\n",
            "45505\n",
            "45506\n",
            "45507\n",
            "45508\n",
            "45509\n",
            "45510\n",
            "45511\n",
            "45512\n",
            "45513\n",
            "45514\n",
            "45515\n",
            "45516\n",
            "45517\n",
            "45518\n",
            "45519\n",
            "45520\n",
            "45521\n",
            "45522\n",
            "45523\n",
            "45524\n",
            "45525\n",
            "45526\n",
            "45527\n",
            "45528\n",
            "45529\n",
            "45530\n",
            "45531\n",
            "45532\n",
            "45533\n",
            "45534\n",
            "45535\n",
            "45536\n",
            "45537\n",
            "45538\n",
            "45539\n",
            "45540\n",
            "45541\n",
            "45542\n",
            "45543\n",
            "45544\n",
            "45545\n",
            "45546\n",
            "45547\n",
            "45548\n",
            "45549\n",
            "45550\n",
            "45551\n",
            "45552\n",
            "45553\n",
            "45554\n",
            "45555\n",
            "45556\n",
            "45557\n",
            "45558\n",
            "45559\n",
            "45560\n",
            "45561\n",
            "45562\n",
            "45563\n",
            "45564\n",
            "45565\n",
            "45566\n",
            "45567\n",
            "45568\n",
            "45569\n",
            "45570\n",
            "45571\n",
            "45572\n",
            "45573\n",
            "45574\n",
            "45575\n",
            "45576\n",
            "45577\n",
            "45578\n",
            "45579\n",
            "45580\n",
            "45581\n",
            "45582\n",
            "45583\n",
            "45584\n",
            "45585\n",
            "45586\n",
            "45587\n",
            "45588\n",
            "45589\n",
            "45590\n",
            "45591\n",
            "45592\n",
            "45593\n",
            "45594\n",
            "45595\n",
            "45596\n",
            "45597\n",
            "45598\n",
            "45599\n",
            "45600\n",
            "45601\n",
            "45602\n",
            "45603\n",
            "45604\n",
            "45605\n",
            "45606\n",
            "45607\n",
            "45608\n",
            "45609\n",
            "45610\n",
            "45611\n",
            "45612\n",
            "45613\n",
            "45614\n",
            "45615\n",
            "45616\n",
            "45617\n",
            "45618\n",
            "45619\n",
            "45620\n",
            "45621\n",
            "45622\n",
            "45623\n",
            "45624\n",
            "45625\n",
            "45626\n",
            "45627\n",
            "45628\n",
            "45629\n",
            "45630\n",
            "45631\n",
            "45632\n",
            "45633\n",
            "45634\n",
            "45635\n",
            "45636\n",
            "45637\n",
            "45638\n",
            "45639\n",
            "45640\n",
            "45641\n",
            "45642\n",
            "45643\n",
            "45644\n",
            "45645\n",
            "45646\n",
            "45647\n",
            "45648\n",
            "45649\n",
            "45650\n",
            "45651\n",
            "45652\n",
            "45653\n",
            "45654\n",
            "45655\n",
            "45656\n",
            "45657\n",
            "45658\n",
            "45659\n",
            "45660\n",
            "45661\n",
            "45662\n",
            "45663\n",
            "45664\n",
            "45665\n",
            "45666\n",
            "45667\n",
            "45668\n",
            "45669\n",
            "45670\n",
            "45671\n",
            "45672\n",
            "45673\n",
            "45674\n",
            "45675\n",
            "45676\n",
            "45677\n",
            "45678\n",
            "45679\n",
            "45680\n",
            "45681\n",
            "45682\n",
            "45683\n",
            "45684\n",
            "45685\n",
            "45686\n",
            "45687\n",
            "45688\n",
            "45689\n",
            "45690\n",
            "45691\n",
            "45692\n",
            "45693\n",
            "45694\n",
            "45695\n",
            "45696\n",
            "45697\n",
            "45698\n",
            "45699\n",
            "45700\n",
            "45701\n",
            "45702\n",
            "45703\n",
            "45704\n",
            "45705\n",
            "45706\n",
            "45707\n",
            "45708\n",
            "45709\n",
            "45710\n",
            "45711\n",
            "45712\n",
            "45713\n",
            "45714\n",
            "45715\n",
            "45716\n",
            "45717\n",
            "45718\n",
            "45719\n",
            "45720\n",
            "45721\n",
            "45722\n",
            "45723\n",
            "45724\n",
            "45725\n",
            "45726\n",
            "45727\n",
            "45728\n",
            "45729\n",
            "45730\n",
            "45731\n",
            "45732\n",
            "45733\n",
            "45734\n",
            "45735\n",
            "45736\n",
            "45737\n",
            "45738\n",
            "45739\n",
            "45740\n",
            "45741\n",
            "45742\n",
            "45743\n",
            "45744\n",
            "45745\n",
            "45746\n",
            "45747\n",
            "45748\n",
            "45749\n",
            "45750\n",
            "45751\n",
            "45752\n",
            "45753\n",
            "45754\n",
            "45755\n",
            "45756\n",
            "45757\n",
            "45758\n",
            "45759\n",
            "45760\n",
            "45761\n",
            "45762\n",
            "45763\n",
            "45764\n",
            "45765\n",
            "45766\n",
            "45767\n",
            "45768\n",
            "45769\n",
            "45770\n",
            "45771\n",
            "45772\n",
            "45773\n",
            "45774\n",
            "45775\n",
            "45776\n",
            "45777\n",
            "45778\n",
            "45779\n",
            "45780\n",
            "45781\n",
            "45782\n",
            "45783\n",
            "45784\n",
            "45785\n",
            "45786\n",
            "45787\n",
            "45788\n",
            "45789\n",
            "45790\n",
            "45791\n",
            "45792\n",
            "45793\n",
            "45794\n",
            "45795\n",
            "45796\n",
            "45797\n",
            "45798\n",
            "45799\n",
            "45800\n",
            "45801\n",
            "45802\n",
            "45803\n",
            "45804\n",
            "45805\n",
            "45806\n",
            "45807\n",
            "45808\n",
            "45809\n",
            "45810\n",
            "45811\n",
            "45812\n",
            "45813\n",
            "45814\n",
            "45815\n",
            "45816\n",
            "45817\n",
            "45818\n",
            "45819\n",
            "45820\n",
            "45821\n",
            "45822\n",
            "45823\n",
            "45824\n",
            "45825\n",
            "45826\n",
            "45827\n",
            "45828\n",
            "45829\n",
            "45830\n",
            "45831\n",
            "45832\n",
            "45833\n",
            "45834\n",
            "45835\n",
            "45836\n",
            "45837\n",
            "45838\n",
            "45839\n",
            "45840\n",
            "45841\n",
            "45842\n",
            "45843\n",
            "45844\n",
            "45845\n",
            "45846\n",
            "45847\n",
            "45848\n",
            "45849\n",
            "45850\n",
            "45851\n",
            "45852\n",
            "45853\n",
            "45854\n",
            "45855\n",
            "45856\n",
            "45857\n",
            "45858\n",
            "45859\n",
            "45860\n",
            "45861\n",
            "45862\n",
            "45863\n",
            "45864\n",
            "45865\n",
            "45866\n",
            "45867\n",
            "45868\n",
            "45869\n",
            "45870\n",
            "45871\n",
            "45872\n",
            "45873\n",
            "45874\n",
            "45875\n",
            "45876\n",
            "45877\n",
            "45878\n",
            "45879\n",
            "45880\n",
            "45881\n",
            "45882\n",
            "45883\n",
            "45884\n",
            "45885\n",
            "45886\n",
            "45887\n",
            "45888\n",
            "45889\n",
            "45890\n",
            "45891\n",
            "45892\n",
            "45893\n",
            "45894\n",
            "45895\n",
            "45896\n",
            "45897\n",
            "45898\n",
            "45899\n",
            "45900\n",
            "45901\n",
            "45902\n",
            "45903\n",
            "45904\n",
            "45905\n",
            "45906\n",
            "45907\n",
            "45908\n",
            "45909\n",
            "45910\n",
            "45911\n",
            "45912\n",
            "45913\n",
            "45914\n",
            "45915\n",
            "45916\n",
            "45917\n",
            "45918\n",
            "45919\n",
            "45920\n",
            "45921\n",
            "45922\n",
            "45923\n",
            "45924\n",
            "45925\n",
            "45926\n",
            "45927\n",
            "45928\n",
            "45929\n",
            "45930\n",
            "45931\n",
            "45932\n",
            "45933\n",
            "45934\n",
            "45935\n",
            "45936\n",
            "45937\n",
            "45938\n",
            "45939\n",
            "45940\n",
            "45941\n",
            "45942\n",
            "45943\n",
            "45944\n",
            "45945\n",
            "45946\n",
            "45947\n",
            "45948\n",
            "45949\n",
            "45950\n",
            "45951\n",
            "45952\n",
            "45953\n",
            "45954\n",
            "45955\n",
            "45956\n",
            "45957\n",
            "45958\n",
            "45959\n",
            "45960\n",
            "45961\n",
            "45962\n",
            "45963\n",
            "45964\n",
            "45965\n",
            "45966\n",
            "45967\n",
            "45968\n",
            "45969\n",
            "45970\n",
            "45971\n",
            "45972\n",
            "45973\n",
            "45974\n",
            "45975\n",
            "45976\n",
            "45977\n",
            "45978\n",
            "45979\n",
            "45980\n",
            "45981\n",
            "45982\n",
            "45983\n",
            "45984\n",
            "45985\n",
            "45986\n",
            "45987\n",
            "45988\n",
            "45989\n",
            "45990\n",
            "45991\n",
            "45992\n",
            "45993\n",
            "45994\n",
            "45995\n",
            "45996\n",
            "45997\n",
            "45998\n",
            "45999\n",
            "46000\n",
            "46001\n",
            "46002\n",
            "46003\n",
            "46004\n",
            "46005\n",
            "46006\n",
            "46007\n",
            "46008\n",
            "46009\n",
            "46010\n",
            "46011\n",
            "46012\n",
            "46013\n",
            "46014\n",
            "46015\n",
            "46016\n",
            "46017\n",
            "46018\n",
            "46019\n",
            "46020\n",
            "46021\n",
            "46022\n",
            "46023\n",
            "46024\n",
            "46025\n",
            "46026\n",
            "46027\n",
            "46028\n",
            "46029\n",
            "46030\n",
            "46031\n",
            "46032\n",
            "46033\n",
            "46034\n",
            "46035\n",
            "46036\n",
            "46037\n",
            "46038\n",
            "46039\n",
            "46040\n",
            "46041\n",
            "46042\n",
            "46043\n",
            "46044\n",
            "46045\n",
            "46046\n",
            "46047\n",
            "46048\n",
            "46049\n",
            "46050\n",
            "46051\n",
            "46052\n",
            "46053\n",
            "46054\n",
            "46055\n",
            "46056\n",
            "46057\n",
            "46058\n",
            "46059\n",
            "46060\n",
            "46061\n",
            "46062\n",
            "46063\n",
            "46064\n",
            "46065\n",
            "46066\n",
            "46067\n",
            "46068\n",
            "46069\n",
            "46070\n",
            "46071\n",
            "46072\n",
            "46073\n",
            "46074\n",
            "46075\n",
            "46076\n",
            "46077\n",
            "46078\n",
            "46079\n",
            "46080\n",
            "46081\n",
            "46082\n",
            "46083\n",
            "46084\n",
            "46085\n",
            "46086\n",
            "46087\n",
            "46088\n",
            "46089\n",
            "46090\n",
            "46091\n",
            "46092\n",
            "46093\n",
            "46094\n",
            "46095\n",
            "46096\n",
            "46097\n",
            "46098\n",
            "46099\n",
            "46100\n",
            "46101\n",
            "46102\n",
            "46103\n",
            "46104\n",
            "46105\n",
            "46106\n",
            "46107\n",
            "46108\n",
            "46109\n",
            "46110\n",
            "46111\n",
            "46112\n",
            "46113\n",
            "46114\n",
            "46115\n",
            "46116\n",
            "46117\n",
            "46118\n",
            "46119\n",
            "46120\n",
            "46121\n",
            "46122\n",
            "46123\n",
            "46124\n",
            "46125\n",
            "46126\n",
            "46127\n",
            "46128\n",
            "46129\n",
            "46130\n",
            "46131\n",
            "46132\n",
            "46133\n",
            "46134\n",
            "46135\n",
            "46136\n",
            "46137\n",
            "46138\n",
            "46139\n",
            "46140\n",
            "46141\n",
            "46142\n",
            "46143\n",
            "46144\n",
            "46145\n",
            "46146\n",
            "46147\n",
            "46148\n",
            "46149\n",
            "46150\n",
            "46151\n",
            "46152\n",
            "46153\n",
            "46154\n",
            "46155\n",
            "46156\n",
            "46157\n",
            "46158\n",
            "46159\n",
            "46160\n",
            "46161\n",
            "46162\n",
            "46163\n",
            "46164\n",
            "46165\n",
            "46166\n",
            "46167\n",
            "46168\n",
            "46169\n",
            "46170\n",
            "46171\n",
            "46172\n",
            "46173\n",
            "46174\n",
            "46175\n",
            "46176\n",
            "46177\n",
            "46178\n",
            "46179\n",
            "46180\n",
            "46181\n",
            "46182\n",
            "46183\n",
            "46184\n",
            "46185\n",
            "46186\n",
            "46187\n",
            "46188\n",
            "46189\n",
            "46190\n",
            "46191\n",
            "46192\n",
            "46193\n",
            "46194\n",
            "46195\n",
            "46196\n",
            "46197\n",
            "46198\n",
            "46199\n",
            "46200\n",
            "46201\n",
            "46202\n",
            "46203\n",
            "46204\n",
            "46205\n",
            "46206\n",
            "46207\n",
            "46208\n",
            "46209\n",
            "46210\n",
            "46211\n",
            "46212\n",
            "46213\n",
            "46214\n",
            "46215\n",
            "46216\n",
            "46217\n",
            "46218\n",
            "46219\n",
            "46220\n",
            "46221\n",
            "46222\n",
            "46223\n",
            "46224\n",
            "46225\n",
            "46226\n",
            "46227\n",
            "46228\n",
            "46229\n",
            "46230\n",
            "46231\n",
            "46232\n",
            "46233\n",
            "46234\n",
            "46235\n",
            "46236\n",
            "46237\n",
            "46238\n",
            "46239\n",
            "46240\n",
            "46241\n",
            "46242\n",
            "46243\n",
            "46244\n",
            "46245\n",
            "46246\n",
            "46247\n",
            "46248\n",
            "46249\n",
            "46250\n",
            "46251\n",
            "46252\n",
            "46253\n",
            "46254\n",
            "46255\n",
            "46256\n",
            "46257\n",
            "46258\n",
            "46259\n",
            "46260\n",
            "46261\n",
            "46262\n",
            "46263\n",
            "46264\n",
            "46265\n",
            "46266\n",
            "46267\n",
            "46268\n",
            "46269\n",
            "46270\n",
            "46271\n",
            "46272\n",
            "46273\n",
            "46274\n",
            "46275\n",
            "46276\n",
            "46277\n",
            "46278\n",
            "46279\n",
            "46280\n",
            "46281\n",
            "46282\n",
            "46283\n",
            "46284\n",
            "46285\n",
            "46286\n",
            "46287\n",
            "46288\n",
            "46289\n",
            "46290\n",
            "46291\n",
            "46292\n",
            "46293\n",
            "46294\n",
            "46295\n",
            "46296\n",
            "46297\n",
            "46298\n",
            "46299\n",
            "46300\n",
            "46301\n",
            "46302\n",
            "46303\n",
            "46304\n",
            "46305\n",
            "46306\n",
            "46307\n",
            "46308\n",
            "46309\n",
            "46310\n",
            "46311\n",
            "46312\n",
            "46313\n",
            "46314\n",
            "46315\n",
            "46316\n",
            "46317\n",
            "46318\n",
            "46319\n",
            "46320\n",
            "46321\n",
            "46322\n",
            "46323\n",
            "46324\n",
            "46325\n",
            "46326\n",
            "46327\n",
            "46328\n",
            "46329\n",
            "46330\n",
            "46331\n",
            "46332\n",
            "46333\n",
            "46334\n",
            "46335\n",
            "46336\n",
            "46337\n",
            "46338\n",
            "46339\n",
            "46340\n",
            "46341\n",
            "46342\n",
            "46343\n",
            "46344\n",
            "46345\n",
            "46346\n",
            "46347\n",
            "46348\n",
            "46349\n",
            "46350\n",
            "46351\n",
            "46352\n",
            "46353\n",
            "46354\n",
            "46355\n",
            "46356\n",
            "46357\n",
            "46358\n",
            "46359\n",
            "46360\n",
            "46361\n",
            "46362\n",
            "46363\n",
            "46364\n",
            "46365\n",
            "46366\n",
            "46367\n",
            "46368\n",
            "46369\n",
            "46370\n",
            "46371\n",
            "46372\n",
            "46373\n",
            "46374\n",
            "46375\n",
            "46376\n",
            "46377\n",
            "46378\n",
            "46379\n",
            "46380\n",
            "46381\n",
            "46382\n",
            "46383\n",
            "46384\n",
            "46385\n",
            "46386\n",
            "46387\n",
            "46388\n",
            "46389\n",
            "46390\n",
            "46391\n",
            "46392\n",
            "46393\n",
            "46394\n",
            "46395\n",
            "46396\n",
            "46397\n",
            "46398\n",
            "46399\n",
            "46400\n",
            "46401\n",
            "46402\n",
            "46403\n",
            "46404\n",
            "46405\n",
            "46406\n",
            "46407\n",
            "46408\n",
            "46409\n",
            "46410\n",
            "46411\n",
            "46412\n",
            "46413\n",
            "46414\n",
            "46415\n",
            "46416\n",
            "46417\n",
            "46418\n",
            "46419\n",
            "46420\n",
            "46421\n",
            "46422\n",
            "46423\n",
            "46424\n",
            "46425\n",
            "46426\n",
            "46427\n",
            "46428\n",
            "46429\n",
            "46430\n",
            "46431\n",
            "46432\n",
            "46433\n",
            "46434\n",
            "46435\n",
            "46436\n",
            "46437\n",
            "46438\n",
            "46439\n",
            "46440\n",
            "46441\n",
            "46442\n",
            "46443\n",
            "46444\n",
            "46445\n",
            "46446\n",
            "46447\n",
            "46448\n",
            "46449\n",
            "46450\n",
            "46451\n",
            "46452\n",
            "46453\n",
            "46454\n",
            "46455\n",
            "46456\n",
            "46457\n",
            "46458\n",
            "46459\n",
            "46460\n",
            "46461\n",
            "46462\n",
            "46463\n",
            "46464\n",
            "46465\n",
            "46466\n",
            "46467\n",
            "46468\n",
            "46469\n",
            "46470\n",
            "46471\n",
            "46472\n",
            "46473\n",
            "46474\n",
            "46475\n",
            "46476\n",
            "46477\n",
            "46478\n",
            "46479\n",
            "46480\n",
            "46481\n",
            "46482\n",
            "46483\n",
            "46484\n",
            "46485\n",
            "46486\n",
            "46487\n",
            "46488\n",
            "46489\n",
            "46490\n",
            "46491\n",
            "46492\n",
            "46493\n",
            "46494\n",
            "46495\n",
            "46496\n",
            "46497\n",
            "46498\n",
            "46499\n",
            "46500\n",
            "46501\n",
            "46502\n",
            "46503\n",
            "46504\n",
            "46505\n",
            "46506\n",
            "46507\n",
            "46508\n",
            "46509\n",
            "46510\n",
            "46511\n",
            "46512\n",
            "46513\n",
            "46514\n",
            "46515\n",
            "46516\n",
            "46517\n",
            "46518\n",
            "46519\n",
            "46520\n",
            "46521\n",
            "46522\n",
            "46523\n",
            "46524\n",
            "46525\n",
            "46526\n",
            "46527\n",
            "46528\n",
            "46529\n",
            "46530\n",
            "46531\n",
            "46532\n",
            "46533\n",
            "46534\n",
            "46535\n",
            "46536\n",
            "46537\n",
            "46538\n",
            "46539\n",
            "46540\n",
            "46541\n",
            "46542\n",
            "46543\n",
            "46544\n",
            "46545\n",
            "46546\n",
            "46547\n",
            "46548\n",
            "46549\n",
            "46550\n",
            "46551\n",
            "46552\n",
            "46553\n",
            "46554\n",
            "46555\n",
            "46556\n",
            "46557\n",
            "46558\n",
            "46559\n",
            "46560\n",
            "46561\n",
            "46562\n",
            "46563\n",
            "46564\n",
            "46565\n",
            "46566\n",
            "46567\n",
            "46568\n",
            "46569\n",
            "46570\n",
            "46571\n",
            "46572\n",
            "46573\n",
            "46574\n",
            "46575\n",
            "46576\n",
            "46577\n",
            "46578\n",
            "46579\n",
            "46580\n",
            "46581\n",
            "46582\n",
            "46583\n",
            "46584\n",
            "46585\n",
            "46586\n",
            "46587\n",
            "46588\n",
            "46589\n",
            "46590\n",
            "46591\n",
            "46592\n",
            "46593\n",
            "46594\n",
            "46595\n",
            "46596\n",
            "46597\n",
            "46598\n",
            "46599\n",
            "46600\n",
            "46601\n",
            "46602\n",
            "46603\n",
            "46604\n",
            "46605\n",
            "46606\n",
            "46607\n",
            "46608\n",
            "46609\n",
            "46610\n",
            "46611\n",
            "46612\n",
            "46613\n",
            "46614\n",
            "46615\n",
            "46616\n",
            "46617\n",
            "46618\n",
            "46619\n",
            "46620\n",
            "46621\n",
            "46622\n",
            "46623\n",
            "46624\n",
            "46625\n",
            "46626\n",
            "46627\n",
            "46628\n",
            "46629\n",
            "46630\n",
            "46631\n",
            "46632\n",
            "46633\n",
            "46634\n",
            "46635\n",
            "46636\n",
            "46637\n",
            "46638\n",
            "46639\n",
            "46640\n",
            "46641\n",
            "46642\n",
            "46643\n",
            "46644\n",
            "46645\n",
            "46646\n",
            "46647\n",
            "46648\n",
            "46649\n",
            "46650\n",
            "46651\n",
            "46652\n",
            "46653\n",
            "46654\n",
            "46655\n",
            "46656\n",
            "46657\n",
            "46658\n",
            "46659\n",
            "46660\n",
            "46661\n",
            "46662\n",
            "46663\n",
            "46664\n",
            "46665\n",
            "46666\n",
            "46667\n",
            "46668\n",
            "46669\n",
            "46670\n",
            "46671\n",
            "46672\n",
            "46673\n",
            "46674\n",
            "46675\n",
            "46676\n",
            "46677\n",
            "46678\n",
            "46679\n",
            "46680\n",
            "46681\n",
            "46682\n",
            "46683\n",
            "46684\n",
            "46685\n",
            "46686\n",
            "46687\n",
            "46688\n",
            "46689\n",
            "46690\n",
            "46691\n",
            "46692\n",
            "46693\n",
            "46694\n",
            "46695\n",
            "46696\n",
            "46697\n",
            "46698\n",
            "46699\n",
            "46700\n",
            "46701\n",
            "46702\n",
            "46703\n",
            "46704\n",
            "46705\n",
            "46706\n",
            "46707\n",
            "46708\n",
            "46709\n",
            "46710\n",
            "46711\n",
            "46712\n",
            "46713\n",
            "46714\n",
            "46715\n",
            "46716\n",
            "46717\n",
            "46718\n",
            "46719\n",
            "46720\n",
            "46721\n",
            "46722\n",
            "46723\n",
            "46724\n",
            "46725\n",
            "46726\n",
            "46727\n",
            "46728\n",
            "46729\n",
            "46730\n",
            "46731\n",
            "46732\n",
            "46733\n",
            "46734\n",
            "46735\n",
            "46736\n",
            "46737\n",
            "46738\n",
            "46739\n",
            "46740\n",
            "46741\n",
            "46742\n",
            "46743\n",
            "46744\n",
            "46745\n",
            "46746\n",
            "46747\n",
            "46748\n",
            "46749\n",
            "46750\n",
            "46751\n",
            "46752\n",
            "46753\n",
            "46754\n",
            "46755\n",
            "46756\n",
            "46757\n",
            "46758\n",
            "46759\n",
            "46760\n",
            "46761\n",
            "46762\n",
            "46763\n",
            "46764\n",
            "46765\n",
            "46766\n",
            "46767\n",
            "46768\n",
            "46769\n",
            "46770\n",
            "46771\n",
            "46772\n",
            "46773\n",
            "46774\n",
            "46775\n",
            "46776\n",
            "46777\n",
            "46778\n",
            "46779\n",
            "46780\n",
            "46781\n",
            "46782\n",
            "46783\n",
            "46784\n",
            "46785\n",
            "46786\n",
            "46787\n",
            "46788\n",
            "46789\n",
            "46790\n",
            "46791\n",
            "46792\n",
            "46793\n",
            "46794\n",
            "46795\n",
            "46796\n",
            "46797\n",
            "46798\n",
            "46799\n",
            "46800\n",
            "46801\n",
            "46802\n",
            "46803\n",
            "46804\n",
            "46805\n",
            "46806\n",
            "46807\n",
            "46808\n",
            "46809\n",
            "46810\n",
            "46811\n",
            "46812\n",
            "46813\n",
            "46814\n",
            "46815\n",
            "46816\n",
            "46817\n",
            "46818\n",
            "46819\n",
            "46820\n",
            "46821\n",
            "46822\n",
            "46823\n",
            "46824\n",
            "46825\n",
            "46826\n",
            "46827\n",
            "46828\n",
            "46829\n",
            "46830\n",
            "46831\n",
            "46832\n",
            "46833\n",
            "46834\n",
            "46835\n",
            "46836\n",
            "46837\n",
            "46838\n",
            "46839\n",
            "46840\n",
            "46841\n",
            "46842\n",
            "46843\n",
            "46844\n",
            "46845\n",
            "46846\n",
            "46847\n",
            "46848\n",
            "46849\n",
            "46850\n",
            "46851\n",
            "46852\n",
            "46853\n",
            "46854\n",
            "46855\n",
            "46856\n",
            "46857\n",
            "46858\n",
            "46859\n",
            "46860\n",
            "46861\n",
            "46862\n",
            "46863\n",
            "46864\n",
            "46865\n",
            "46866\n",
            "46867\n",
            "46868\n",
            "46869\n",
            "46870\n",
            "46871\n",
            "46872\n",
            "46873\n",
            "46874\n",
            "46875\n",
            "46876\n",
            "46877\n",
            "46878\n",
            "46879\n",
            "46880\n",
            "46881\n",
            "46882\n",
            "46883\n",
            "46884\n",
            "46885\n",
            "46886\n",
            "46887\n",
            "46888\n",
            "46889\n",
            "46890\n",
            "46891\n",
            "46892\n",
            "46893\n",
            "46894\n",
            "46895\n",
            "46896\n",
            "46897\n",
            "46898\n",
            "46899\n",
            "46900\n",
            "46901\n",
            "46902\n",
            "46903\n",
            "46904\n",
            "46905\n",
            "46906\n",
            "46907\n",
            "46908\n",
            "46909\n",
            "46910\n",
            "46911\n",
            "46912\n",
            "46913\n",
            "46914\n",
            "46915\n",
            "46916\n",
            "46917\n",
            "46918\n",
            "46919\n",
            "46920\n",
            "46921\n",
            "46922\n",
            "46923\n",
            "46924\n",
            "46925\n",
            "46926\n",
            "46927\n",
            "46928\n",
            "46929\n",
            "46930\n",
            "46931\n",
            "46932\n",
            "46933\n",
            "46934\n",
            "46935\n",
            "46936\n",
            "46937\n",
            "46938\n",
            "46939\n",
            "46940\n",
            "46941\n",
            "46942\n",
            "46943\n",
            "46944\n",
            "46945\n",
            "46946\n",
            "46947\n",
            "46948\n",
            "46949\n",
            "46950\n",
            "46951\n",
            "46952\n",
            "46953\n",
            "46954\n",
            "46955\n",
            "46956\n",
            "46957\n",
            "46958\n",
            "46959\n",
            "46960\n",
            "46961\n",
            "46962\n",
            "46963\n",
            "46964\n",
            "46965\n",
            "46966\n",
            "46967\n",
            "46968\n",
            "46969\n",
            "46970\n",
            "46971\n",
            "46972\n",
            "46973\n",
            "46974\n",
            "46975\n",
            "46976\n",
            "46977\n",
            "46978\n",
            "46979\n",
            "46980\n",
            "46981\n",
            "46982\n",
            "46983\n",
            "46984\n",
            "46985\n",
            "46986\n",
            "46987\n",
            "46988\n",
            "46989\n",
            "46990\n",
            "46991\n",
            "46992\n",
            "46993\n",
            "46994\n",
            "46995\n",
            "46996\n",
            "46997\n",
            "46998\n",
            "46999\n",
            "47000\n",
            "47001\n",
            "47002\n",
            "47003\n",
            "47004\n",
            "47005\n",
            "47006\n",
            "47007\n",
            "47008\n",
            "47009\n",
            "47010\n",
            "47011\n",
            "47012\n",
            "47013\n",
            "47014\n",
            "47015\n",
            "47016\n",
            "47017\n",
            "47018\n",
            "47019\n",
            "47020\n",
            "47021\n",
            "47022\n",
            "47023\n",
            "47024\n",
            "47025\n",
            "47026\n",
            "47027\n",
            "47028\n",
            "47029\n",
            "47030\n",
            "47031\n",
            "47032\n",
            "47033\n",
            "47034\n",
            "47035\n",
            "47036\n",
            "47037\n",
            "47038\n",
            "47039\n",
            "47040\n",
            "47041\n",
            "47042\n",
            "47043\n",
            "47044\n",
            "47045\n",
            "47046\n",
            "47047\n",
            "47048\n",
            "47049\n",
            "47050\n",
            "47051\n",
            "47052\n",
            "47053\n",
            "47054\n",
            "47055\n",
            "47056\n",
            "47057\n",
            "47058\n",
            "47059\n",
            "47060\n",
            "47061\n",
            "47062\n",
            "47063\n",
            "47064\n",
            "47065\n",
            "47066\n",
            "47067\n",
            "47068\n",
            "47069\n",
            "47070\n",
            "47071\n",
            "47072\n",
            "47073\n",
            "47074\n",
            "47075\n",
            "47076\n",
            "47077\n",
            "47078\n",
            "47079\n",
            "47080\n",
            "47081\n",
            "47082\n",
            "47083\n",
            "47084\n",
            "47085\n",
            "47086\n",
            "47087\n",
            "47088\n",
            "47089\n",
            "47090\n",
            "47091\n",
            "47092\n",
            "47093\n",
            "47094\n",
            "47095\n",
            "47096\n",
            "47097\n",
            "47098\n",
            "47099\n",
            "47100\n",
            "47101\n",
            "47102\n",
            "47103\n",
            "47104\n",
            "47105\n",
            "47106\n",
            "47107\n",
            "47108\n",
            "47109\n",
            "47110\n",
            "47111\n",
            "47112\n",
            "47113\n",
            "47114\n",
            "47115\n",
            "47116\n",
            "47117\n",
            "47118\n",
            "47119\n",
            "47120\n",
            "47121\n",
            "47122\n",
            "47123\n",
            "47124\n",
            "47125\n",
            "47126\n",
            "47127\n",
            "47128\n",
            "47129\n",
            "47130\n",
            "47131\n",
            "47132\n",
            "47133\n",
            "47134\n",
            "47135\n",
            "47136\n",
            "47137\n",
            "47138\n",
            "47139\n",
            "47140\n",
            "47141\n",
            "47142\n",
            "47143\n",
            "47144\n",
            "47145\n",
            "47146\n",
            "47147\n",
            "47148\n",
            "47149\n",
            "47150\n",
            "47151\n",
            "47152\n",
            "47153\n",
            "47154\n",
            "47155\n",
            "47156\n",
            "47157\n",
            "47158\n",
            "47159\n",
            "47160\n",
            "47161\n",
            "47162\n",
            "47163\n",
            "47164\n",
            "47165\n",
            "47166\n",
            "47167\n",
            "47168\n",
            "47169\n",
            "47170\n",
            "47171\n",
            "47172\n",
            "47173\n",
            "47174\n",
            "47175\n",
            "47176\n",
            "47177\n",
            "47178\n",
            "47179\n",
            "47180\n",
            "47181\n",
            "47182\n",
            "47183\n",
            "47184\n",
            "47185\n",
            "47186\n",
            "47187\n",
            "47188\n",
            "47189\n",
            "47190\n",
            "47191\n",
            "47192\n",
            "47193\n",
            "47194\n",
            "47195\n",
            "47196\n",
            "47197\n",
            "47198\n",
            "47199\n",
            "47200\n",
            "47201\n",
            "47202\n",
            "47203\n",
            "47204\n",
            "47205\n",
            "47206\n",
            "47207\n",
            "47208\n",
            "47209\n",
            "47210\n",
            "47211\n",
            "47212\n",
            "47213\n",
            "47214\n",
            "47215\n",
            "47216\n",
            "47217\n",
            "47218\n",
            "47219\n",
            "47220\n",
            "47221\n",
            "47222\n",
            "47223\n",
            "47224\n",
            "47225\n",
            "47226\n",
            "47227\n",
            "47228\n",
            "47229\n",
            "47230\n",
            "47231\n",
            "47232\n",
            "47233\n",
            "47234\n",
            "47235\n",
            "47236\n",
            "47237\n",
            "47238\n",
            "47239\n",
            "47240\n",
            "47241\n",
            "47242\n",
            "47243\n",
            "47244\n",
            "47245\n",
            "47246\n",
            "47247\n",
            "47248\n",
            "47249\n",
            "47250\n",
            "47251\n",
            "47252\n",
            "47253\n",
            "47254\n",
            "47255\n",
            "47256\n",
            "47257\n",
            "47258\n",
            "47259\n",
            "47260\n",
            "47261\n",
            "47262\n",
            "47263\n",
            "47264\n",
            "47265\n",
            "47266\n",
            "47267\n",
            "47268\n",
            "47269\n",
            "47270\n",
            "47271\n",
            "47272\n",
            "47273\n",
            "47274\n",
            "47275\n",
            "47276\n",
            "47277\n",
            "47278\n",
            "47279\n",
            "47280\n",
            "47281\n",
            "47282\n",
            "47283\n",
            "47284\n",
            "47285\n",
            "47286\n",
            "47287\n",
            "47288\n",
            "47289\n",
            "47290\n",
            "47291\n",
            "47292\n",
            "47293\n",
            "47294\n",
            "47295\n",
            "47296\n",
            "47297\n",
            "47298\n",
            "47299\n",
            "47300\n",
            "47301\n",
            "47302\n",
            "47303\n",
            "47304\n",
            "47305\n",
            "47306\n",
            "47307\n",
            "47308\n",
            "47309\n",
            "47310\n",
            "47311\n",
            "47312\n",
            "47313\n",
            "47314\n",
            "47315\n",
            "47316\n",
            "47317\n",
            "47318\n",
            "47319\n",
            "47320\n",
            "47321\n",
            "47322\n",
            "47323\n",
            "47324\n",
            "47325\n",
            "47326\n",
            "47327\n",
            "47328\n",
            "47329\n",
            "47330\n",
            "47331\n",
            "47332\n",
            "47333\n",
            "47334\n",
            "47335\n",
            "47336\n",
            "47337\n",
            "47338\n",
            "47339\n",
            "47340\n",
            "47341\n",
            "47342\n",
            "47343\n",
            "47344\n",
            "47345\n",
            "47346\n",
            "47347\n",
            "47348\n",
            "47349\n",
            "47350\n",
            "47351\n",
            "47352\n",
            "47353\n",
            "47354\n",
            "47355\n",
            "47356\n",
            "47357\n",
            "47358\n",
            "47359\n",
            "47360\n",
            "47361\n",
            "47362\n",
            "47363\n",
            "47364\n",
            "47365\n",
            "47366\n",
            "47367\n",
            "47368\n",
            "47369\n",
            "47370\n",
            "47371\n",
            "47372\n",
            "47373\n",
            "47374\n",
            "47375\n",
            "47376\n",
            "47377\n",
            "47378\n",
            "47379\n",
            "47380\n",
            "47381\n",
            "47382\n",
            "47383\n",
            "47384\n",
            "47385\n",
            "47386\n",
            "47387\n",
            "47388\n",
            "47389\n",
            "47390\n",
            "47391\n",
            "47392\n",
            "47393\n",
            "47394\n",
            "47395\n",
            "47396\n",
            "47397\n",
            "47398\n",
            "47399\n",
            "47400\n",
            "47401\n",
            "47402\n",
            "47403\n",
            "47404\n",
            "47405\n",
            "47406\n",
            "47407\n",
            "47408\n",
            "47409\n",
            "47410\n",
            "47411\n",
            "47412\n",
            "47413\n",
            "47414\n",
            "47415\n",
            "47416\n",
            "47417\n",
            "47418\n",
            "47419\n",
            "47420\n",
            "47421\n",
            "47422\n",
            "47423\n",
            "47424\n",
            "47425\n",
            "47426\n",
            "47427\n",
            "47428\n",
            "47429\n",
            "47430\n",
            "47431\n",
            "47432\n",
            "47433\n",
            "47434\n",
            "47435\n",
            "47436\n",
            "47437\n",
            "47438\n",
            "47439\n",
            "47440\n",
            "47441\n",
            "47442\n",
            "47443\n",
            "47444\n",
            "47445\n",
            "47446\n",
            "47447\n",
            "47448\n",
            "47449\n",
            "47450\n",
            "47451\n",
            "47452\n",
            "47453\n",
            "47454\n",
            "47455\n",
            "47456\n",
            "47457\n",
            "47458\n",
            "47459\n",
            "47460\n",
            "47461\n",
            "47462\n",
            "47463\n",
            "47464\n",
            "47465\n",
            "47466\n",
            "47467\n",
            "47468\n",
            "47469\n",
            "47470\n",
            "47471\n",
            "47472\n",
            "47473\n",
            "47474\n",
            "47475\n",
            "47476\n",
            "47477\n",
            "47478\n",
            "47479\n",
            "47480\n",
            "47481\n",
            "47482\n",
            "47483\n",
            "47484\n",
            "47485\n",
            "47486\n",
            "47487\n",
            "47488\n",
            "47489\n",
            "47490\n",
            "47491\n",
            "47492\n",
            "47493\n",
            "47494\n",
            "47495\n",
            "47496\n",
            "47497\n",
            "47498\n",
            "47499\n",
            "47500\n",
            "47501\n",
            "47502\n",
            "47503\n",
            "47504\n",
            "47505\n",
            "47506\n",
            "47507\n",
            "47508\n",
            "47509\n",
            "47510\n",
            "47511\n",
            "47512\n",
            "47513\n",
            "47514\n",
            "47515\n",
            "47516\n",
            "47517\n",
            "47518\n",
            "47519\n",
            "47520\n",
            "47521\n",
            "47522\n",
            "47523\n",
            "47524\n",
            "47525\n",
            "47526\n",
            "47527\n",
            "47528\n",
            "47529\n",
            "47530\n",
            "47531\n",
            "47532\n",
            "47533\n",
            "47534\n",
            "47535\n",
            "47536\n",
            "47537\n",
            "47538\n",
            "47539\n",
            "47540\n",
            "47541\n",
            "47542\n",
            "47543\n",
            "47544\n",
            "47545\n",
            "47546\n",
            "47547\n",
            "47548\n",
            "47549\n",
            "47550\n",
            "47551\n",
            "47552\n",
            "47553\n",
            "47554\n",
            "47555\n",
            "47556\n",
            "47557\n",
            "47558\n",
            "47559\n",
            "47560\n",
            "47561\n",
            "47562\n",
            "47563\n",
            "47564\n",
            "47565\n",
            "47566\n",
            "47567\n",
            "47568\n",
            "47569\n",
            "47570\n",
            "47571\n",
            "47572\n",
            "47573\n",
            "47574\n",
            "47575\n",
            "47576\n",
            "47577\n",
            "47578\n",
            "47579\n",
            "47580\n",
            "47581\n",
            "47582\n",
            "47583\n",
            "47584\n",
            "47585\n",
            "47586\n",
            "47587\n",
            "47588\n",
            "47589\n",
            "47590\n",
            "47591\n",
            "47592\n",
            "47593\n",
            "47594\n",
            "47595\n",
            "47596\n",
            "47597\n",
            "47598\n",
            "47599\n",
            "47600\n",
            "47601\n",
            "47602\n",
            "47603\n",
            "47604\n",
            "47605\n",
            "47606\n",
            "47607\n",
            "47608\n",
            "47609\n",
            "47610\n",
            "47611\n",
            "47612\n",
            "47613\n",
            "47614\n",
            "47615\n",
            "47616\n",
            "47617\n",
            "47618\n",
            "47619\n",
            "47620\n",
            "47621\n",
            "47622\n",
            "47623\n",
            "47624\n",
            "47625\n",
            "47626\n",
            "47627\n",
            "47628\n",
            "47629\n",
            "47630\n",
            "47631\n",
            "47632\n",
            "47633\n",
            "47634\n",
            "47635\n",
            "47636\n",
            "47637\n",
            "47638\n",
            "47639\n",
            "47640\n",
            "47641\n",
            "47642\n",
            "47643\n",
            "47644\n",
            "47645\n",
            "47646\n",
            "47647\n",
            "47648\n",
            "47649\n",
            "47650\n",
            "47651\n",
            "47652\n",
            "47653\n",
            "47654\n",
            "47655\n",
            "47656\n",
            "47657\n",
            "47658\n",
            "47659\n",
            "47660\n",
            "47661\n",
            "47662\n",
            "47663\n",
            "47664\n",
            "47665\n",
            "47666\n",
            "47667\n",
            "47668\n",
            "47669\n",
            "47670\n",
            "47671\n",
            "47672\n",
            "47673\n",
            "47674\n",
            "47675\n",
            "47676\n",
            "47677\n",
            "47678\n",
            "47679\n",
            "47680\n",
            "47681\n",
            "47682\n",
            "47683\n",
            "47684\n",
            "47685\n",
            "47686\n",
            "47687\n",
            "47688\n",
            "47689\n",
            "47690\n",
            "47691\n",
            "47692\n",
            "47693\n",
            "47694\n",
            "47695\n",
            "47696\n",
            "47697\n",
            "47698\n",
            "47699\n",
            "47700\n",
            "47701\n",
            "47702\n",
            "47703\n",
            "47704\n",
            "47705\n",
            "47706\n",
            "47707\n",
            "47708\n",
            "47709\n",
            "47710\n",
            "47711\n",
            "47712\n",
            "47713\n",
            "47714\n",
            "47715\n",
            "47716\n",
            "47717\n",
            "47718\n",
            "47719\n",
            "47720\n",
            "47721\n",
            "47722\n",
            "47723\n",
            "47724\n",
            "47725\n",
            "47726\n",
            "47727\n",
            "47728\n",
            "47729\n",
            "47730\n",
            "47731\n",
            "47732\n",
            "47733\n",
            "47734\n",
            "47735\n",
            "47736\n",
            "47737\n",
            "47738\n",
            "47739\n",
            "47740\n",
            "47741\n",
            "47742\n",
            "47743\n",
            "47744\n",
            "47745\n",
            "47746\n",
            "47747\n",
            "47748\n",
            "47749\n",
            "47750\n",
            "47751\n",
            "47752\n",
            "47753\n",
            "47754\n",
            "47755\n",
            "47756\n",
            "47757\n",
            "47758\n",
            "47759\n",
            "47760\n",
            "47761\n",
            "47762\n",
            "47763\n",
            "47764\n",
            "47765\n",
            "47766\n",
            "47767\n",
            "47768\n",
            "47769\n",
            "47770\n",
            "47771\n",
            "47772\n",
            "47773\n",
            "47774\n",
            "47775\n",
            "47776\n",
            "47777\n",
            "47778\n",
            "47779\n",
            "47780\n",
            "47781\n",
            "47782\n",
            "47783\n",
            "47784\n",
            "47785\n",
            "47786\n",
            "47787\n",
            "47788\n",
            "47789\n",
            "47790\n",
            "47791\n",
            "47792\n",
            "47793\n",
            "47794\n",
            "47795\n",
            "47796\n",
            "47797\n",
            "47798\n",
            "47799\n",
            "47800\n",
            "47801\n",
            "47802\n",
            "47803\n",
            "47804\n",
            "47805\n",
            "47806\n",
            "47807\n",
            "47808\n",
            "47809\n",
            "47810\n",
            "47811\n",
            "47812\n",
            "47813\n",
            "47814\n",
            "47815\n",
            "47816\n",
            "47817\n",
            "47818\n",
            "47819\n",
            "47820\n",
            "47821\n",
            "47822\n",
            "47823\n",
            "47824\n",
            "47825\n",
            "47826\n",
            "47827\n",
            "47828\n",
            "47829\n",
            "47830\n",
            "47831\n",
            "47832\n",
            "47833\n",
            "47834\n",
            "47835\n",
            "47836\n",
            "47837\n",
            "47838\n",
            "47839\n",
            "47840\n",
            "47841\n",
            "47842\n",
            "47843\n",
            "47844\n",
            "47845\n",
            "47846\n",
            "47847\n",
            "47848\n",
            "47849\n",
            "47850\n",
            "47851\n",
            "47852\n",
            "47853\n",
            "47854\n",
            "47855\n",
            "47856\n",
            "47857\n",
            "47858\n",
            "47859\n",
            "47860\n",
            "47861\n",
            "47862\n",
            "47863\n",
            "47864\n",
            "47865\n",
            "47866\n",
            "47867\n",
            "47868\n",
            "47869\n",
            "47870\n",
            "47871\n",
            "47872\n",
            "47873\n",
            "47874\n",
            "47875\n",
            "47876\n",
            "47877\n",
            "47878\n",
            "47879\n",
            "47880\n",
            "47881\n",
            "47882\n",
            "47883\n",
            "47884\n",
            "47885\n",
            "47886\n",
            "47887\n",
            "47888\n",
            "47889\n",
            "47890\n",
            "47891\n",
            "47892\n",
            "47893\n",
            "47894\n",
            "47895\n",
            "47896\n",
            "47897\n",
            "47898\n",
            "47899\n",
            "47900\n",
            "47901\n",
            "47902\n",
            "47903\n",
            "47904\n",
            "47905\n",
            "47906\n",
            "47907\n",
            "47908\n",
            "47909\n",
            "47910\n",
            "47911\n",
            "47912\n",
            "47913\n",
            "47914\n",
            "47915\n",
            "47916\n",
            "47917\n",
            "47918\n",
            "47919\n",
            "47920\n",
            "47921\n",
            "47922\n",
            "47923\n",
            "47924\n",
            "47925\n",
            "47926\n",
            "47927\n",
            "47928\n",
            "47929\n",
            "47930\n",
            "47931\n",
            "47932\n",
            "47933\n",
            "47934\n",
            "47935\n",
            "47936\n",
            "47937\n",
            "47938\n",
            "47939\n",
            "47940\n",
            "47941\n",
            "47942\n",
            "47943\n",
            "47944\n",
            "47945\n",
            "47946\n",
            "47947\n",
            "47948\n",
            "47949\n",
            "47950\n",
            "47951\n",
            "47952\n",
            "47953\n",
            "47954\n",
            "47955\n",
            "47956\n",
            "47957\n",
            "47958\n",
            "47959\n",
            "47960\n",
            "47961\n",
            "47962\n",
            "47963\n",
            "47964\n",
            "47965\n",
            "47966\n",
            "47967\n",
            "47968\n",
            "47969\n",
            "47970\n",
            "47971\n",
            "47972\n",
            "47973\n",
            "47974\n",
            "47975\n",
            "47976\n",
            "47977\n",
            "47978\n",
            "47979\n",
            "47980\n",
            "47981\n",
            "47982\n",
            "47983\n",
            "47984\n",
            "47985\n",
            "47986\n",
            "47987\n",
            "47988\n",
            "47989\n",
            "47990\n",
            "47991\n",
            "47992\n",
            "47993\n",
            "47994\n",
            "47995\n",
            "47996\n",
            "47997\n",
            "47998\n",
            "47999\n",
            "48000\n",
            "48001\n",
            "48002\n",
            "48003\n",
            "48004\n",
            "48005\n",
            "48006\n",
            "48007\n",
            "48008\n",
            "48009\n",
            "48010\n",
            "48011\n",
            "48012\n",
            "48013\n",
            "48014\n",
            "48015\n",
            "48016\n",
            "48017\n",
            "48018\n",
            "48019\n",
            "48020\n",
            "48021\n",
            "48022\n",
            "48023\n",
            "48024\n",
            "48025\n",
            "48026\n",
            "48027\n",
            "48028\n",
            "48029\n",
            "48030\n",
            "48031\n",
            "48032\n",
            "48033\n",
            "48034\n",
            "48035\n",
            "48036\n",
            "48037\n",
            "48038\n",
            "48039\n",
            "48040\n",
            "48041\n",
            "48042\n",
            "48043\n",
            "48044\n",
            "48045\n",
            "48046\n",
            "48047\n",
            "48048\n",
            "48049\n",
            "48050\n",
            "48051\n",
            "48052\n",
            "48053\n",
            "48054\n",
            "48055\n",
            "48056\n",
            "48057\n",
            "48058\n",
            "48059\n",
            "48060\n",
            "48061\n",
            "48062\n",
            "48063\n",
            "48064\n",
            "48065\n",
            "48066\n",
            "48067\n",
            "48068\n",
            "48069\n",
            "48070\n",
            "48071\n",
            "48072\n",
            "48073\n",
            "48074\n",
            "48075\n",
            "48076\n",
            "48077\n",
            "48078\n",
            "48079\n",
            "48080\n",
            "48081\n",
            "48082\n",
            "48083\n",
            "48084\n",
            "48085\n",
            "48086\n",
            "48087\n",
            "48088\n",
            "48089\n",
            "48090\n",
            "48091\n",
            "48092\n",
            "48093\n",
            "48094\n",
            "48095\n",
            "48096\n",
            "48097\n",
            "48098\n",
            "48099\n",
            "48100\n",
            "48101\n",
            "48102\n",
            "48103\n",
            "48104\n",
            "48105\n",
            "48106\n",
            "48107\n",
            "48108\n",
            "48109\n",
            "48110\n",
            "48111\n",
            "48112\n",
            "48113\n",
            "48114\n",
            "48115\n",
            "48116\n",
            "48117\n",
            "48118\n",
            "48119\n",
            "48120\n",
            "48121\n",
            "48122\n",
            "48123\n",
            "48124\n",
            "48125\n",
            "48126\n",
            "48127\n",
            "48128\n",
            "48129\n",
            "48130\n",
            "48131\n",
            "48132\n",
            "48133\n",
            "48134\n",
            "48135\n",
            "48136\n",
            "48137\n",
            "48138\n",
            "48139\n",
            "48140\n",
            "48141\n",
            "48142\n",
            "48143\n",
            "48144\n",
            "48145\n",
            "48146\n",
            "48147\n",
            "48148\n",
            "48149\n",
            "48150\n",
            "48151\n",
            "48152\n",
            "48153\n",
            "48154\n",
            "48155\n",
            "48156\n",
            "48157\n",
            "48158\n",
            "48159\n",
            "48160\n",
            "48161\n",
            "48162\n",
            "48163\n",
            "48164\n",
            "48165\n",
            "48166\n",
            "48167\n",
            "48168\n",
            "48169\n",
            "48170\n",
            "48171\n",
            "48172\n",
            "48173\n",
            "48174\n",
            "48175\n",
            "48176\n",
            "48177\n",
            "48178\n",
            "48179\n",
            "48180\n",
            "48181\n",
            "48182\n",
            "48183\n",
            "48184\n",
            "48185\n",
            "48186\n",
            "48187\n",
            "48188\n",
            "48189\n",
            "48190\n",
            "48191\n",
            "48192\n",
            "48193\n",
            "48194\n",
            "48195\n",
            "48196\n",
            "48197\n",
            "48198\n",
            "48199\n",
            "48200\n",
            "48201\n",
            "48202\n",
            "48203\n",
            "48204\n",
            "48205\n",
            "48206\n",
            "48207\n",
            "48208\n",
            "48209\n",
            "48210\n",
            "48211\n",
            "48212\n",
            "48213\n",
            "48214\n",
            "48215\n",
            "48216\n",
            "48217\n",
            "48218\n",
            "48219\n",
            "48220\n",
            "48221\n",
            "48222\n",
            "48223\n",
            "48224\n",
            "48225\n",
            "48226\n",
            "48227\n",
            "48228\n",
            "48229\n",
            "48230\n",
            "48231\n",
            "48232\n",
            "48233\n",
            "48234\n",
            "48235\n",
            "48236\n",
            "48237\n",
            "48238\n",
            "48239\n",
            "48240\n",
            "48241\n",
            "48242\n",
            "48243\n",
            "48244\n",
            "48245\n",
            "48246\n",
            "48247\n",
            "48248\n",
            "48249\n",
            "48250\n",
            "48251\n",
            "48252\n",
            "48253\n",
            "48254\n",
            "48255\n",
            "48256\n",
            "48257\n",
            "48258\n",
            "48259\n",
            "48260\n",
            "48261\n",
            "48262\n",
            "48263\n",
            "48264\n",
            "48265\n",
            "48266\n",
            "48267\n",
            "48268\n",
            "48269\n",
            "48270\n",
            "48271\n",
            "48272\n",
            "48273\n",
            "48274\n",
            "48275\n",
            "48276\n",
            "48277\n",
            "48278\n",
            "48279\n",
            "48280\n",
            "48281\n",
            "48282\n",
            "48283\n",
            "48284\n",
            "48285\n",
            "48286\n",
            "48287\n",
            "48288\n",
            "48289\n",
            "48290\n",
            "48291\n",
            "48292\n",
            "48293\n",
            "48294\n",
            "48295\n",
            "48296\n",
            "48297\n",
            "48298\n",
            "48299\n",
            "48300\n",
            "48301\n",
            "48302\n",
            "48303\n",
            "48304\n",
            "48305\n",
            "48306\n",
            "48307\n",
            "48308\n",
            "48309\n",
            "48310\n",
            "48311\n",
            "48312\n",
            "48313\n",
            "48314\n",
            "48315\n",
            "48316\n",
            "48317\n",
            "48318\n",
            "48319\n",
            "48320\n",
            "48321\n",
            "48322\n",
            "48323\n",
            "48324\n",
            "48325\n",
            "48326\n",
            "48327\n",
            "48328\n",
            "48329\n",
            "48330\n",
            "48331\n",
            "48332\n",
            "48333\n",
            "48334\n",
            "48335\n",
            "48336\n",
            "48337\n",
            "48338\n",
            "48339\n",
            "48340\n",
            "48341\n",
            "48342\n",
            "48343\n",
            "48344\n",
            "48345\n",
            "48346\n",
            "48347\n",
            "48348\n",
            "48349\n",
            "48350\n",
            "48351\n",
            "48352\n",
            "48353\n",
            "48354\n",
            "48355\n",
            "48356\n",
            "48357\n",
            "48358\n",
            "48359\n",
            "48360\n",
            "48361\n",
            "48362\n",
            "48363\n",
            "48364\n",
            "48365\n",
            "48366\n",
            "48367\n",
            "48368\n",
            "48369\n",
            "48370\n",
            "48371\n",
            "48372\n",
            "48373\n",
            "48374\n",
            "48375\n",
            "48376\n",
            "48377\n",
            "48378\n",
            "48379\n",
            "48380\n",
            "48381\n",
            "48382\n",
            "48383\n",
            "48384\n",
            "48385\n",
            "48386\n",
            "48387\n",
            "48388\n",
            "48389\n",
            "48390\n",
            "48391\n",
            "48392\n",
            "48393\n",
            "48394\n",
            "48395\n",
            "48396\n",
            "48397\n",
            "48398\n",
            "48399\n",
            "48400\n",
            "48401\n",
            "48402\n",
            "48403\n",
            "48404\n",
            "48405\n",
            "48406\n",
            "48407\n",
            "48408\n",
            "48409\n",
            "48410\n",
            "48411\n",
            "48412\n",
            "48413\n",
            "48414\n",
            "48415\n",
            "48416\n",
            "48417\n",
            "48418\n",
            "48419\n",
            "48420\n",
            "48421\n",
            "48422\n",
            "48423\n",
            "48424\n",
            "48425\n",
            "48426\n",
            "48427\n",
            "48428\n",
            "48429\n",
            "48430\n",
            "48431\n",
            "48432\n",
            "48433\n",
            "48434\n",
            "48435\n",
            "48436\n",
            "48437\n",
            "48438\n",
            "48439\n",
            "48440\n",
            "48441\n",
            "48442\n",
            "48443\n",
            "48444\n",
            "48445\n",
            "48446\n",
            "48447\n",
            "48448\n",
            "48449\n",
            "48450\n",
            "48451\n",
            "48452\n",
            "48453\n",
            "48454\n",
            "48455\n",
            "48456\n",
            "48457\n",
            "48458\n",
            "48459\n",
            "48460\n",
            "48461\n",
            "48462\n",
            "48463\n",
            "48464\n",
            "48465\n",
            "48466\n",
            "48467\n",
            "48468\n",
            "48469\n",
            "48470\n",
            "48471\n",
            "48472\n",
            "48473\n",
            "48474\n",
            "48475\n",
            "48476\n",
            "48477\n",
            "48478\n",
            "48479\n",
            "48480\n",
            "48481\n",
            "48482\n",
            "48483\n",
            "48484\n",
            "48485\n",
            "48486\n",
            "48487\n",
            "48488\n",
            "48489\n",
            "48490\n",
            "48491\n",
            "48492\n",
            "48493\n",
            "48494\n",
            "48495\n",
            "48496\n",
            "48497\n",
            "48498\n",
            "48499\n",
            "48500\n",
            "48501\n",
            "48502\n",
            "48503\n",
            "48504\n",
            "48505\n",
            "48506\n",
            "48507\n",
            "48508\n",
            "48509\n",
            "48510\n",
            "48511\n",
            "48512\n",
            "48513\n",
            "48514\n",
            "48515\n",
            "48516\n",
            "48517\n",
            "48518\n",
            "48519\n",
            "48520\n",
            "48521\n",
            "48522\n",
            "48523\n",
            "48524\n",
            "48525\n",
            "48526\n",
            "48527\n",
            "48528\n",
            "48529\n",
            "48530\n",
            "48531\n",
            "48532\n",
            "48533\n",
            "48534\n",
            "48535\n",
            "48536\n",
            "48537\n",
            "48538\n",
            "48539\n",
            "48540\n",
            "48541\n",
            "48542\n",
            "48543\n",
            "48544\n",
            "48545\n",
            "48546\n",
            "48547\n",
            "48548\n",
            "48549\n",
            "48550\n",
            "48551\n",
            "48552\n",
            "48553\n",
            "48554\n",
            "48555\n",
            "48556\n",
            "48557\n",
            "48558\n",
            "48559\n",
            "48560\n",
            "48561\n",
            "48562\n",
            "48563\n",
            "48564\n",
            "48565\n",
            "48566\n",
            "48567\n",
            "48568\n",
            "48569\n",
            "48570\n",
            "48571\n",
            "48572\n",
            "48573\n",
            "48574\n",
            "48575\n",
            "48576\n",
            "48577\n",
            "48578\n",
            "48579\n",
            "48580\n",
            "48581\n",
            "48582\n",
            "48583\n",
            "48584\n",
            "48585\n",
            "48586\n",
            "48587\n",
            "48588\n",
            "48589\n",
            "48590\n",
            "48591\n",
            "48592\n",
            "48593\n",
            "48594\n",
            "48595\n",
            "48596\n",
            "48597\n",
            "48598\n",
            "48599\n",
            "48600\n",
            "48601\n",
            "48602\n",
            "48603\n",
            "48604\n",
            "48605\n",
            "48606\n",
            "48607\n",
            "48608\n",
            "48609\n",
            "48610\n",
            "48611\n",
            "48612\n",
            "48613\n",
            "48614\n",
            "48615\n",
            "48616\n",
            "48617\n",
            "48618\n",
            "48619\n",
            "48620\n",
            "48621\n",
            "48622\n",
            "48623\n",
            "48624\n",
            "48625\n",
            "48626\n",
            "48627\n",
            "48628\n",
            "48629\n",
            "48630\n",
            "48631\n",
            "48632\n",
            "48633\n",
            "48634\n",
            "48635\n",
            "48636\n",
            "48637\n",
            "48638\n",
            "48639\n",
            "48640\n",
            "48641\n",
            "48642\n",
            "48643\n",
            "48644\n",
            "48645\n",
            "48646\n",
            "48647\n",
            "48648\n",
            "48649\n",
            "48650\n",
            "48651\n",
            "48652\n",
            "48653\n",
            "48654\n",
            "48655\n",
            "48656\n",
            "48657\n",
            "48658\n",
            "48659\n",
            "48660\n",
            "48661\n",
            "48662\n",
            "48663\n",
            "48664\n",
            "48665\n",
            "48666\n",
            "48667\n",
            "48668\n",
            "48669\n",
            "48670\n",
            "48671\n",
            "48672\n",
            "48673\n",
            "48674\n",
            "48675\n",
            "48676\n",
            "48677\n",
            "48678\n",
            "48679\n",
            "48680\n",
            "48681\n",
            "48682\n",
            "48683\n",
            "48684\n",
            "48685\n",
            "48686\n",
            "48687\n",
            "48688\n",
            "48689\n",
            "48690\n",
            "48691\n",
            "48692\n",
            "48693\n",
            "48694\n",
            "48695\n",
            "48696\n",
            "48697\n",
            "48698\n",
            "48699\n",
            "48700\n",
            "48701\n",
            "48702\n",
            "48703\n",
            "48704\n",
            "48705\n",
            "48706\n",
            "48707\n",
            "48708\n",
            "48709\n",
            "48710\n",
            "48711\n",
            "48712\n",
            "48713\n",
            "48714\n",
            "48715\n",
            "48716\n",
            "48717\n",
            "48718\n",
            "48719\n",
            "48720\n",
            "48721\n",
            "48722\n",
            "48723\n",
            "48724\n",
            "48725\n",
            "48726\n",
            "48727\n",
            "48728\n",
            "48729\n",
            "48730\n",
            "48731\n",
            "48732\n",
            "48733\n",
            "48734\n",
            "48735\n",
            "48736\n",
            "48737\n",
            "48738\n",
            "48739\n",
            "48740\n",
            "48741\n",
            "48742\n",
            "48743\n",
            "48744\n",
            "48745\n",
            "48746\n",
            "48747\n",
            "48748\n",
            "48749\n",
            "48750\n",
            "48751\n",
            "48752\n",
            "48753\n",
            "48754\n",
            "48755\n",
            "48756\n",
            "48757\n",
            "48758\n",
            "48759\n",
            "48760\n",
            "48761\n",
            "48762\n",
            "48763\n",
            "48764\n",
            "48765\n",
            "48766\n",
            "48767\n",
            "48768\n",
            "48769\n",
            "48770\n",
            "48771\n",
            "48772\n",
            "48773\n",
            "48774\n",
            "48775\n",
            "48776\n",
            "48777\n",
            "48778\n",
            "48779\n",
            "48780\n",
            "48781\n",
            "48782\n",
            "48783\n",
            "48784\n",
            "48785\n",
            "48786\n",
            "48787\n",
            "48788\n",
            "48789\n",
            "48790\n",
            "48791\n",
            "48792\n",
            "48793\n",
            "48794\n",
            "48795\n",
            "48796\n",
            "48797\n",
            "48798\n",
            "48799\n",
            "48800\n",
            "48801\n",
            "48802\n",
            "48803\n",
            "48804\n",
            "48805\n",
            "48806\n",
            "48807\n",
            "48808\n",
            "48809\n",
            "48810\n",
            "48811\n",
            "48812\n",
            "48813\n",
            "48814\n",
            "48815\n",
            "48816\n",
            "48817\n",
            "48818\n",
            "48819\n",
            "48820\n",
            "48821\n",
            "48822\n",
            "48823\n",
            "48824\n",
            "48825\n",
            "48826\n",
            "48827\n",
            "48828\n",
            "48829\n",
            "48830\n",
            "48831\n",
            "48832\n",
            "48833\n",
            "48834\n",
            "48835\n",
            "48836\n",
            "48837\n",
            "48838\n",
            "48839\n",
            "48840\n",
            "48841\n",
            "48842\n",
            "48843\n",
            "48844\n",
            "48845\n",
            "48846\n",
            "48847\n",
            "48848\n",
            "48849\n",
            "48850\n",
            "48851\n",
            "48852\n",
            "48853\n",
            "48854\n",
            "48855\n",
            "48856\n",
            "48857\n",
            "48858\n",
            "48859\n",
            "48860\n",
            "48861\n",
            "48862\n",
            "48863\n",
            "48864\n",
            "48865\n",
            "48866\n",
            "48867\n",
            "48868\n",
            "48869\n",
            "48870\n",
            "48871\n",
            "48872\n",
            "48873\n",
            "48874\n",
            "48875\n",
            "48876\n",
            "48877\n",
            "48878\n",
            "48879\n",
            "48880\n",
            "48881\n",
            "48882\n",
            "48883\n",
            "48884\n",
            "48885\n",
            "48886\n",
            "48887\n",
            "48888\n",
            "48889\n",
            "48890\n",
            "48891\n",
            "48892\n",
            "48893\n",
            "48894\n",
            "48895\n",
            "48896\n",
            "48897\n",
            "48898\n",
            "48899\n",
            "48900\n",
            "48901\n",
            "48902\n",
            "48903\n",
            "48904\n",
            "48905\n",
            "48906\n",
            "48907\n",
            "48908\n",
            "48909\n",
            "48910\n",
            "48911\n",
            "48912\n",
            "48913\n",
            "48914\n",
            "48915\n",
            "48916\n",
            "48917\n",
            "48918\n",
            "48919\n",
            "48920\n",
            "48921\n",
            "48922\n",
            "48923\n",
            "48924\n",
            "48925\n",
            "48926\n",
            "48927\n",
            "48928\n",
            "48929\n",
            "48930\n",
            "48931\n",
            "48932\n",
            "48933\n",
            "48934\n",
            "48935\n",
            "48936\n",
            "48937\n",
            "48938\n",
            "48939\n",
            "48940\n",
            "48941\n",
            "48942\n",
            "48943\n",
            "48944\n",
            "48945\n",
            "48946\n",
            "48947\n",
            "48948\n",
            "48949\n",
            "48950\n",
            "48951\n",
            "48952\n",
            "48953\n",
            "48954\n",
            "48955\n",
            "48956\n",
            "48957\n",
            "48958\n",
            "48959\n",
            "48960\n",
            "48961\n",
            "48962\n",
            "48963\n",
            "48964\n",
            "48965\n",
            "48966\n",
            "48967\n",
            "48968\n",
            "48969\n",
            "48970\n",
            "48971\n",
            "48972\n",
            "48973\n",
            "48974\n",
            "48975\n",
            "48976\n",
            "48977\n",
            "48978\n",
            "48979\n",
            "48980\n",
            "48981\n",
            "48982\n",
            "48983\n",
            "48984\n",
            "48985\n",
            "48986\n",
            "48987\n",
            "48988\n",
            "48989\n",
            "48990\n",
            "48991\n",
            "48992\n",
            "48993\n",
            "48994\n",
            "48995\n",
            "48996\n",
            "48997\n",
            "48998\n",
            "48999\n",
            "49000\n",
            "49001\n",
            "49002\n",
            "49003\n",
            "49004\n",
            "49005\n",
            "49006\n",
            "49007\n",
            "49008\n",
            "49009\n",
            "49010\n",
            "49011\n",
            "49012\n",
            "49013\n",
            "49014\n",
            "49015\n",
            "49016\n",
            "49017\n",
            "49018\n",
            "49019\n",
            "49020\n",
            "49021\n",
            "49022\n",
            "49023\n",
            "49024\n",
            "49025\n",
            "49026\n",
            "49027\n",
            "49028\n",
            "49029\n",
            "49030\n",
            "49031\n",
            "49032\n",
            "49033\n",
            "49034\n",
            "49035\n",
            "49036\n",
            "49037\n",
            "49038\n",
            "49039\n",
            "49040\n",
            "49041\n",
            "49042\n",
            "49043\n",
            "49044\n",
            "49045\n",
            "49046\n",
            "49047\n",
            "49048\n",
            "49049\n",
            "49050\n",
            "49051\n",
            "49052\n",
            "49053\n",
            "49054\n",
            "49055\n",
            "49056\n",
            "49057\n",
            "49058\n",
            "49059\n",
            "49060\n",
            "49061\n",
            "49062\n",
            "49063\n",
            "49064\n",
            "49065\n",
            "49066\n",
            "49067\n",
            "49068\n",
            "49069\n",
            "49070\n",
            "49071\n",
            "49072\n",
            "49073\n",
            "49074\n",
            "49075\n",
            "49076\n",
            "49077\n",
            "49078\n",
            "49079\n",
            "49080\n",
            "49081\n",
            "49082\n",
            "49083\n",
            "49084\n",
            "49085\n",
            "49086\n",
            "49087\n",
            "49088\n",
            "49089\n",
            "49090\n",
            "49091\n",
            "49092\n",
            "49093\n",
            "49094\n",
            "49095\n",
            "49096\n",
            "49097\n",
            "49098\n",
            "49099\n",
            "49100\n",
            "49101\n",
            "49102\n",
            "49103\n",
            "49104\n",
            "49105\n",
            "49106\n",
            "49107\n",
            "49108\n",
            "49109\n",
            "49110\n",
            "49111\n",
            "49112\n",
            "49113\n",
            "49114\n",
            "49115\n",
            "49116\n",
            "49117\n",
            "49118\n",
            "49119\n",
            "49120\n",
            "49121\n",
            "49122\n",
            "49123\n",
            "49124\n",
            "49125\n",
            "49126\n",
            "49127\n",
            "49128\n",
            "49129\n",
            "49130\n",
            "49131\n",
            "49132\n",
            "49133\n",
            "49134\n",
            "49135\n",
            "49136\n",
            "49137\n",
            "49138\n",
            "49139\n",
            "49140\n",
            "49141\n",
            "49142\n",
            "49143\n",
            "49144\n",
            "49145\n",
            "49146\n",
            "49147\n",
            "49148\n",
            "49149\n",
            "49150\n",
            "49151\n",
            "49152\n",
            "49153\n",
            "49154\n",
            "49155\n",
            "49156\n",
            "49157\n",
            "49158\n",
            "49159\n",
            "49160\n",
            "49161\n",
            "49162\n",
            "49163\n",
            "49164\n",
            "49165\n",
            "49166\n",
            "49167\n",
            "49168\n",
            "49169\n",
            "49170\n",
            "49171\n",
            "49172\n",
            "49173\n",
            "49174\n",
            "49175\n",
            "49176\n",
            "49177\n",
            "49178\n",
            "49179\n",
            "49180\n",
            "49181\n",
            "49182\n",
            "49183\n",
            "49184\n",
            "49185\n",
            "49186\n",
            "49187\n",
            "49188\n",
            "49189\n",
            "49190\n",
            "49191\n",
            "49192\n",
            "49193\n",
            "49194\n",
            "49195\n",
            "49196\n",
            "49197\n",
            "49198\n",
            "49199\n",
            "49200\n",
            "49201\n",
            "49202\n",
            "49203\n",
            "49204\n",
            "49205\n",
            "49206\n",
            "49207\n",
            "49208\n",
            "49209\n",
            "49210\n",
            "49211\n",
            "49212\n",
            "49213\n",
            "49214\n",
            "49215\n",
            "49216\n",
            "49217\n",
            "49218\n",
            "49219\n",
            "49220\n",
            "49221\n",
            "49222\n",
            "49223\n",
            "49224\n",
            "49225\n",
            "49226\n",
            "49227\n",
            "49228\n",
            "49229\n",
            "49230\n",
            "49231\n",
            "49232\n",
            "49233\n",
            "49234\n",
            "49235\n",
            "49236\n",
            "49237\n",
            "49238\n",
            "49239\n",
            "49240\n",
            "49241\n",
            "49242\n",
            "49243\n",
            "49244\n",
            "49245\n",
            "49246\n",
            "49247\n",
            "49248\n",
            "49249\n",
            "49250\n",
            "49251\n",
            "49252\n",
            "49253\n",
            "49254\n",
            "49255\n",
            "49256\n",
            "49257\n",
            "49258\n",
            "49259\n",
            "49260\n",
            "49261\n",
            "49262\n",
            "49263\n",
            "49264\n",
            "49265\n",
            "49266\n",
            "49267\n",
            "49268\n",
            "49269\n",
            "49270\n",
            "49271\n",
            "49272\n",
            "49273\n",
            "49274\n",
            "49275\n",
            "49276\n",
            "49277\n",
            "49278\n",
            "49279\n",
            "49280\n",
            "49281\n",
            "49282\n",
            "49283\n",
            "49284\n",
            "49285\n",
            "49286\n",
            "49287\n",
            "49288\n",
            "49289\n",
            "49290\n",
            "49291\n",
            "49292\n",
            "49293\n",
            "49294\n",
            "49295\n",
            "49296\n",
            "49297\n",
            "49298\n",
            "49299\n",
            "49300\n",
            "49301\n",
            "49302\n",
            "49303\n",
            "49304\n",
            "49305\n",
            "49306\n",
            "49307\n",
            "49308\n",
            "49309\n",
            "49310\n",
            "49311\n",
            "49312\n",
            "49313\n",
            "49314\n",
            "49315\n",
            "49316\n",
            "49317\n",
            "49318\n",
            "49319\n",
            "49320\n",
            "49321\n",
            "49322\n",
            "49323\n",
            "49324\n",
            "49325\n",
            "49326\n",
            "49327\n",
            "49328\n",
            "49329\n",
            "49330\n",
            "49331\n",
            "49332\n",
            "49333\n",
            "49334\n",
            "49335\n",
            "49336\n",
            "49337\n",
            "49338\n",
            "49339\n",
            "49340\n",
            "49341\n",
            "49342\n",
            "49343\n",
            "49344\n",
            "49345\n",
            "49346\n",
            "49347\n",
            "49348\n",
            "49349\n",
            "49350\n",
            "49351\n",
            "49352\n",
            "49353\n",
            "49354\n",
            "49355\n",
            "49356\n",
            "49357\n",
            "49358\n",
            "49359\n",
            "49360\n",
            "49361\n",
            "49362\n",
            "49363\n",
            "49364\n",
            "49365\n",
            "49366\n",
            "49367\n",
            "49368\n",
            "49369\n",
            "49370\n",
            "49371\n",
            "49372\n",
            "49373\n",
            "49374\n",
            "49375\n",
            "49376\n",
            "49377\n",
            "49378\n",
            "49379\n",
            "49380\n",
            "49381\n",
            "49382\n",
            "49383\n",
            "49384\n",
            "49385\n",
            "49386\n",
            "49387\n",
            "49388\n",
            "49389\n",
            "49390\n",
            "49391\n",
            "49392\n",
            "49393\n",
            "49394\n",
            "49395\n",
            "49396\n",
            "49397\n",
            "49398\n",
            "49399\n",
            "49400\n",
            "49401\n",
            "49402\n",
            "49403\n",
            "49404\n",
            "49405\n",
            "49406\n",
            "49407\n",
            "49408\n",
            "49409\n",
            "49410\n",
            "49411\n",
            "49412\n",
            "49413\n",
            "49414\n",
            "49415\n",
            "49416\n",
            "49417\n",
            "49418\n",
            "49419\n",
            "49420\n",
            "49421\n",
            "49422\n",
            "49423\n",
            "49424\n",
            "49425\n",
            "49426\n",
            "49427\n",
            "49428\n",
            "49429\n",
            "49430\n",
            "49431\n",
            "49432\n",
            "49433\n",
            "49434\n",
            "49435\n",
            "49436\n",
            "49437\n",
            "49438\n",
            "49439\n",
            "49440\n",
            "49441\n",
            "49442\n",
            "49443\n",
            "49444\n",
            "49445\n",
            "49446\n",
            "49447\n",
            "49448\n",
            "49449\n",
            "49450\n",
            "49451\n",
            "49452\n",
            "49453\n",
            "49454\n",
            "49455\n",
            "49456\n",
            "49457\n",
            "49458\n",
            "49459\n",
            "49460\n",
            "49461\n",
            "49462\n",
            "49463\n",
            "49464\n",
            "49465\n",
            "49466\n",
            "49467\n",
            "49468\n",
            "49469\n",
            "49470\n",
            "49471\n",
            "49472\n",
            "49473\n",
            "49474\n",
            "49475\n",
            "49476\n",
            "49477\n",
            "49478\n",
            "49479\n",
            "49480\n",
            "49481\n",
            "49482\n",
            "49483\n",
            "49484\n",
            "49485\n",
            "49486\n",
            "49487\n",
            "49488\n",
            "49489\n",
            "49490\n",
            "49491\n",
            "49492\n",
            "49493\n",
            "49494\n",
            "49495\n",
            "49496\n",
            "49497\n",
            "49498\n",
            "49499\n",
            "49500\n",
            "49501\n",
            "49502\n",
            "49503\n",
            "49504\n",
            "49505\n",
            "49506\n",
            "49507\n",
            "49508\n",
            "49509\n",
            "49510\n",
            "49511\n",
            "49512\n",
            "49513\n",
            "49514\n",
            "49515\n",
            "49516\n",
            "49517\n",
            "49518\n",
            "49519\n",
            "49520\n",
            "49521\n",
            "49522\n",
            "49523\n",
            "49524\n",
            "49525\n",
            "49526\n",
            "49527\n",
            "49528\n",
            "49529\n",
            "49530\n",
            "49531\n",
            "49532\n",
            "49533\n",
            "49534\n",
            "49535\n",
            "49536\n",
            "49537\n",
            "49538\n",
            "49539\n",
            "49540\n",
            "49541\n",
            "49542\n",
            "49543\n",
            "49544\n",
            "49545\n",
            "49546\n",
            "49547\n",
            "49548\n",
            "49549\n",
            "49550\n",
            "49551\n",
            "49552\n",
            "49553\n",
            "49554\n",
            "49555\n",
            "49556\n",
            "49557\n",
            "49558\n",
            "49559\n",
            "49560\n",
            "49561\n",
            "49562\n",
            "49563\n",
            "49564\n",
            "49565\n",
            "49566\n",
            "49567\n",
            "49568\n",
            "49569\n",
            "49570\n",
            "49571\n",
            "49572\n",
            "49573\n",
            "49574\n",
            "49575\n",
            "49576\n",
            "49577\n",
            "49578\n",
            "49579\n",
            "49580\n",
            "49581\n",
            "49582\n",
            "49583\n",
            "49584\n",
            "49585\n",
            "49586\n",
            "49587\n",
            "49588\n",
            "49589\n",
            "49590\n",
            "49591\n",
            "49592\n",
            "49593\n",
            "49594\n",
            "49595\n",
            "49596\n",
            "49597\n",
            "49598\n",
            "49599\n",
            "49600\n",
            "49601\n",
            "49602\n",
            "49603\n",
            "49604\n",
            "49605\n",
            "49606\n",
            "49607\n",
            "49608\n",
            "49609\n",
            "49610\n",
            "49611\n",
            "49612\n",
            "49613\n",
            "49614\n",
            "49615\n",
            "49616\n",
            "49617\n",
            "49618\n",
            "49619\n",
            "49620\n",
            "49621\n",
            "49622\n",
            "49623\n",
            "49624\n",
            "49625\n",
            "49626\n",
            "49627\n",
            "49628\n",
            "49629\n",
            "49630\n",
            "49631\n",
            "49632\n",
            "49633\n",
            "49634\n",
            "49635\n",
            "49636\n",
            "49637\n",
            "49638\n",
            "49639\n",
            "49640\n",
            "49641\n",
            "49642\n",
            "49643\n",
            "49644\n",
            "49645\n",
            "49646\n",
            "49647\n",
            "49648\n",
            "49649\n",
            "49650\n",
            "49651\n",
            "49652\n",
            "49653\n",
            "49654\n",
            "49655\n",
            "49656\n",
            "49657\n",
            "49658\n",
            "49659\n",
            "49660\n",
            "49661\n",
            "49662\n",
            "49663\n",
            "49664\n",
            "49665\n",
            "49666\n",
            "49667\n",
            "49668\n",
            "49669\n",
            "49670\n",
            "49671\n",
            "49672\n",
            "49673\n",
            "49674\n",
            "49675\n",
            "49676\n",
            "49677\n",
            "49678\n",
            "49679\n",
            "49680\n",
            "49681\n",
            "49682\n",
            "49683\n",
            "49684\n",
            "49685\n",
            "49686\n",
            "49687\n",
            "49688\n",
            "49689\n",
            "49690\n",
            "49691\n",
            "49692\n",
            "49693\n",
            "49694\n",
            "49695\n",
            "49696\n",
            "49697\n",
            "49698\n",
            "49699\n",
            "49700\n",
            "49701\n",
            "49702\n",
            "49703\n",
            "49704\n",
            "49705\n",
            "49706\n",
            "49707\n",
            "49708\n",
            "49709\n",
            "49710\n",
            "49711\n",
            "49712\n",
            "49713\n",
            "49714\n",
            "49715\n",
            "49716\n",
            "49717\n",
            "49718\n",
            "49719\n",
            "49720\n",
            "49721\n",
            "49722\n",
            "49723\n",
            "49724\n",
            "49725\n",
            "49726\n",
            "49727\n",
            "49728\n",
            "49729\n",
            "49730\n",
            "49731\n",
            "49732\n",
            "49733\n",
            "49734\n",
            "49735\n",
            "49736\n",
            "49737\n",
            "49738\n",
            "49739\n",
            "49740\n",
            "49741\n",
            "49742\n",
            "49743\n",
            "49744\n",
            "49745\n",
            "49746\n",
            "49747\n",
            "49748\n",
            "49749\n",
            "49750\n",
            "49751\n",
            "49752\n",
            "49753\n",
            "49754\n",
            "49755\n",
            "49756\n",
            "49757\n",
            "49758\n",
            "49759\n",
            "49760\n",
            "49761\n",
            "49762\n",
            "49763\n",
            "49764\n",
            "49765\n",
            "49766\n",
            "49767\n",
            "49768\n",
            "49769\n",
            "49770\n",
            "49771\n",
            "49772\n",
            "49773\n",
            "49774\n",
            "49775\n",
            "49776\n",
            "49777\n",
            "49778\n",
            "49779\n",
            "49780\n",
            "49781\n",
            "49782\n",
            "49783\n",
            "49784\n",
            "49785\n",
            "49786\n",
            "49787\n",
            "49788\n",
            "49789\n",
            "49790\n",
            "49791\n"
          ]
        }
      ],
      "source": [
        "# Create folder for sliced images\n",
        "if not os.path.exists('/content/Train_Sliced_Images'):\n",
        "            os.makedirs('/content/Train_Sliced_Images')\n",
        "\n",
        "DEF_SIZE = 128\n",
        "\n",
        "folder_sample = '/content/gdrive/MyDrive/Train_spectogram_Images'\n",
        "directories = [d for d in os.listdir(folder_sample)\n",
        "                 if os.path.isdir(os.path.join(folder_sample, d))]\n",
        "counter = 0             \n",
        "for d in directories:\n",
        "    label_directory = os.path.join(folder_sample, d)\n",
        "    file_names = [os.path.join(label_directory, f)\n",
        "                  for f in os.listdir(label_directory)\n",
        "                  if f.endswith(\".jpg\")]\n",
        "            \n",
        "    for f in file_names:\n",
        "      genre = re.search('/content/gdrive/MyDrive/Train_spectogram_Images/.*/.*_(.+?).jpg', f).group(1)\n",
        "      #print(genre)\n",
        "      img = Image.open(f)\n",
        "      w, h = img.size\n",
        "      # understand how many sliced images for each spectogram\n",
        "      num_slices = w // DEF_SIZE\n",
        "      for i in range(num_slices):\n",
        "        left_ = i*DEF_SIZE  \n",
        "        img_sliced = img.crop((left_, 0., left_+DEF_SIZE, DEF_SIZE)) # left, top, right, bottom\n",
        "        img_sliced.save(\"/content/Train_Sliced_Images/\"+str(counter)+\"_\"+genre+\".jpg\")\n",
        "        counter += 1\n",
        "        #print(counter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8Thow1JETAV"
      },
      "source": [
        "The images are then saved as npy files, easier to manage.\n",
        "\n",
        "The labels are converted in one-hot encoding and splitted into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8XZDHmOR9jI"
      },
      "outputs": [],
      "source": [
        "# Convert the data set into grey-scale images and associate it with the label for the training phase\n",
        "\n",
        "## TO DO CREATE FUNCTION LOAD DATA SET\n",
        "genre = {\n",
        "        \"Hip-Hop\": 0,\n",
        "        \"International\": 1,\n",
        "        \"Electronic\": 2,\n",
        "        \"Folk\" : 3,\n",
        "        \"Experimental\": 4,\n",
        "        \"Rock\": 5,\n",
        "        \"Pop\": 6,\n",
        "        \"Instrumental\": 7\n",
        "        }\n",
        "\n",
        "spectogram_images = [os.path.join('/content/Train_Sliced_Images', f)\n",
        "                          for f in os.listdir('/content/Train_Sliced_Images')\n",
        "                          if f.endswith(\".jpg\")]\n",
        "\n",
        "\n",
        "images_all = [None]*(len(spectogram_images))\n",
        "labels_all = [None]*(len(spectogram_images))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(spectogram_images))\n",
        "for f in spectogram_images:\n",
        "    idx = int(re.search('/content/Train_Sliced_Images/(.+?)_.*.jpg', f).group(1))\n",
        "    genre_var = re.search('/content/Train_Sliced_Images/.*_(.+?).jpg', f).group(1)\n",
        "    \n",
        "    temp = cv2.imread(f, cv2.IMREAD_UNCHANGED)\n",
        "    images_all[idx] = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n",
        "    labels_all[idx] = genre[genre_var]\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBzeeCQPImV9",
        "outputId": "a8fb8e90-0734-4976-babb-a511ce71fd38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.array(images_all)\n",
        "labels = np.array(labels_all)\n",
        "labels = labels.reshape(labels.shape[0],1)\n",
        "train_x, test_x, train_y, test_y = train_test_split(images, labels, test_size=0.1, shuffle=True)"
      ],
      "metadata": {
        "id": "muXnwtQNzrAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the labels into one-hot vectors.\n",
        "n_classes = len(genre)\n",
        "train_y = np_utils.to_categorical(train_y, num_classes=n_classes)\n",
        "test_y = np_utils.to_categorical(test_y, num_classes=n_classes)\n",
        "\n",
        "genre_new = {value: key for key, value in genre.items()}\n",
        "\n"
      ],
      "metadata": {
        "id": "3Y7c9cZeztYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists('/content/gdrive/MyDrive/Training_Data_Giulia'):\n",
        "    train_x = np.load(\"/content/gdrive/MyDrive/Training_Data_Giulia/train_x.npy\")\n",
        "    train_y = np.load(\"/content/gdrive/MyDrive/Training_Data_Giulia/train_y.npy\")\n",
        "    test_x = np.load(\"/content/gdrive/MyDrive/Training_Data_Giulia/test_x.npy\")\n",
        "    test_y = np.load(\"/content/gdrive/MyDrive/Training_Data_Giulia/test_y.npy\")\n",
        "    \n",
        "\n",
        "if not os.path.exists('/content/gdrive/MyDrive/Training_Dat_Giuliaa'):\n",
        "    os.makedirs('/content/gdrive/MyDrive/Training_Data_Giulia')\n",
        "np.save(\"/content/gdrive/MyDrive/Training_Data_Giulia/train_x.npy\", train_x)\n",
        "np.save(\"/content/gdrive/MyDrive/Training_Data_Giulia/train_y.npy\", train_y)\n",
        "np.save(\"/content/gdrive/MyDrive/Training_Data_Giulia/test_x.npy\", test_x)\n",
        "np.save(\"/content/gdrive/MyDrive/Training_Data_Giulia/test_y.npy\", test_y)"
      ],
      "metadata": {
        "id": "Pep4HsGEzvGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RanOSdXd4eat"
      },
      "source": [
        "The following model is over-fitting, since it performs well in terms of the training set, but it performs very pooorly in the validation data set.\n",
        "We will try to improve the performance by modifying the architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wBQTcVfd2MIe"
      },
      "outputs": [],
      "source": [
        "train_x = np.load('/content/gdrive/MyDrive/Training_Data_Giulia/train_x.npy')\n",
        "test_x = np.load('/content/gdrive/MyDrive/Training_Data_Giulia/test_x.npy')\n",
        "train_y = np.load('/content/gdrive/MyDrive/Training_Data_Giulia/train_y.npy')\n",
        "test_y = np.load('/content/gdrive/MyDrive/Training_Data_Giulia/test_y.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYgAiEJ45QWe",
        "outputId": "fa602336-20e7-4229-de69-1a66cd3670ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((44811, 8), (44811, 128, 128))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "train_y.shape, train_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5cneAqHw2OTE"
      },
      "outputs": [],
      "source": [
        "train_x_1, val_x, train_y_1, val_y = train_test_split(train_x, train_y, test_size=0.10, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0azIGgD46_M",
        "outputId": "3f3ffaf0-8299-4183-bad8-addc5cf4729d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4482, 128, 128), (4482, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "val_x.shape, val_y.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBFZP-vtMBeo"
      },
      "source": [
        "To shuffle also the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "lpGCrpSP2o1r"
      },
      "outputs": [],
      "source": [
        "# Expand the dimensions of the image to have a channel dimension. (nx128x128) ==> (nx128x128x1)\n",
        "train_x_1 = train_x_1.reshape(train_x_1.shape[0], train_x_1.shape[1], train_x_1.shape[2], 1)\n",
        "test_x = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2], 1)\n",
        "val_x = val_x.reshape(val_x.shape[0], val_x.shape[1], val_x.shape[2], 1)\n",
        "\n",
        "# # Normalize the matrices.\n",
        "# train_x_1 = train_x_1 / 255.\n",
        "# val_x = val_x / 255.\n",
        "# test_x = test_x / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEfl3MZjCRMG"
      },
      "source": [
        "1. prova con early stopping\n",
        "2. aggiungi regularization layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0DxuB-hPD2Ed"
      },
      "outputs": [],
      "source": [
        "# import regularizer\n",
        "from keras import regularizers\n",
        "from keras.regularizers import l2\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((train_x_1, train_y_1))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_x, test_y))"
      ],
      "metadata": {
        "id": "TfVLIaG8iLSE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "pEnRJY2slTiX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AwT0ahVw2iF",
        "outputId": "06d7c889-2d25-47d8-9cc1-b8d5f3fe404e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((128, 128, 1), (8,)), types: (tf.uint8, tf.float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = layers.Rescaling(1./255)\n",
        "val_ds = val_ds.batch(128).map(lambda x, y: (normalization_layer(x), y))\n",
        "test_ds = test_ds.batch(128).map(lambda x, y: (normalization_layer(x), y))"
      ],
      "metadata": {
        "id": "iAZkyCLdn3l_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=8)\n",
        "save_best_model = ModelCheckpoint(filepath='model_.{epoch:02d}_{val_loss:.2f}.hdf5', verbose=1,\n",
        "        monitor='val_loss')\n"
      ],
      "metadata": {
        "id": "s1ApFTPCTOzG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iGJQS27YyKKp",
        "outputId": "f4ad5890-5360-41bb-cdb6-a9fdf6cecdd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 64, 64, 64)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 32, 32, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 128)       32896     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 256)         131328    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 2, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 1, 1, 512)         524800    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 1, 1, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 32)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 8)                 264       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 857,960\n",
            "Trainable params: 857,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "315/315 [==============================] - ETA: 0s - loss: 2.0836 - accuracy: 0.1848\n",
            "Epoch 00001: saving model to model_.01_1.95.hdf5\n",
            "315/315 [==============================] - 83s 240ms/step - loss: 2.0836 - accuracy: 0.1848 - val_loss: 1.9548 - val_accuracy: 0.2536\n",
            "Epoch 2/30\n",
            "315/315 [==============================] - ETA: 0s - loss: 1.9062 - accuracy: 0.2921\n",
            "Epoch 00002: saving model to model_.02_1.84.hdf5\n",
            "315/315 [==============================] - 76s 240ms/step - loss: 1.9062 - accuracy: 0.2921 - val_loss: 1.8432 - val_accuracy: 0.3157\n",
            "Epoch 3/30\n",
            "315/315 [==============================] - ETA: 0s - loss: 1.8353 - accuracy: 0.3317\n",
            "Epoch 00003: saving model to model_.03_1.87.hdf5\n",
            "315/315 [==============================] - 76s 241ms/step - loss: 1.8353 - accuracy: 0.3317 - val_loss: 1.8715 - val_accuracy: 0.3061\n",
            "Epoch 4/30\n",
            "315/315 [==============================] - ETA: 0s - loss: 1.7949 - accuracy: 0.3519\n",
            "Epoch 00004: saving model to model_.04_1.83.hdf5\n",
            "315/315 [==============================] - 89s 282ms/step - loss: 1.7949 - accuracy: 0.3519 - val_loss: 1.8269 - val_accuracy: 0.3249\n",
            "Epoch 5/30\n",
            "315/315 [==============================] - ETA: 0s - loss: 1.7806 - accuracy: 0.3584\n",
            "Epoch 00005: saving model to model_.05_1.82.hdf5\n",
            "315/315 [==============================] - 76s 242ms/step - loss: 1.7806 - accuracy: 0.3584 - val_loss: 1.8175 - val_accuracy: 0.3363\n",
            "Epoch 6/30\n",
            "315/315 [==============================] - ETA: 0s - loss: 1.7620 - accuracy: 0.3708\n",
            "Epoch 00006: saving model to model_.06_1.80.hdf5\n",
            "315/315 [==============================] - 73s 233ms/step - loss: 1.7620 - accuracy: 0.3708 - val_loss: 1.8044 - val_accuracy: 0.3493\n",
            "Epoch 7/30\n",
            "315/315 [==============================] - ETA: 0s - loss: 1.7514 - accuracy: 0.3761\n",
            "Epoch 00007: saving model to model_.07_1.82.hdf5\n",
            "315/315 [==============================] - 74s 234ms/step - loss: 1.7514 - accuracy: 0.3761 - val_loss: 1.8196 - val_accuracy: 0.3397\n",
            "Epoch 8/30\n",
            "315/315 [==============================] - ETA: 0s - loss: 1.7316 - accuracy: 0.3858\n",
            "Epoch 00008: saving model to model_.08_1.84.hdf5\n",
            "315/315 [==============================] - 75s 238ms/step - loss: 1.7316 - accuracy: 0.3858 - val_loss: 1.8406 - val_accuracy: 0.3365\n",
            "Epoch 9/30\n",
            "109/315 [=========>....................] - ETA: 47s - loss: 1.7202 - accuracy: 0.3861"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-7ad081d2b60b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m              metrics = ['accuracy'])\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved_Model/training_history.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if not os.path.exists('Saved_Model'):\n",
        "  os.mkdir('Saved_Model')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "save_best_model = ModelCheckpoint(filepath='model_.{epoch:02d}_{val_loss:.2f}.hdf5', verbose=1,\n",
        "        monitor='val_loss')\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=2, strides=2, activation='elu',kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.0001), input_shape=(128,128,1)))\n",
        "model.add(MaxPooling2D(pool_size=2, padding='same'))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=2, strides=2, activation='elu',kernel_regularizer=regularizers.l2(0.0001), kernel_initializer='glorot_normal'))\n",
        "model.add(MaxPooling2D(pool_size=2, padding='same'))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=2, strides=2, activation='elu', kernel_regularizer=regularizers.l2(0.0001),kernel_initializer='glorot_normal'))\n",
        "model.add(MaxPooling2D(pool_size=2, padding='same'))\n",
        "\n",
        "model.add(Conv2D(filters=512, kernel_size=2, strides=2, activation='elu', kernel_regularizer=regularizers.l2(0.0001),kernel_initializer='glorot_normal'))\n",
        "model.add(MaxPooling2D(pool_size=2, padding='same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Dense(256))\n",
        "\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128))\n",
        "\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('elu'))\n",
        "\n",
        "model.add(Dense(8))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Save the model architecture\n",
        "#plot_model(model, to_file=\"/content/Saved_Model/Model_Architecture.jpg\", show_shapes=True)\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "             metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(train_ds, epochs=30, batch_size=128, verbose=1, validation_data=val_ds, callbacks=[early_stopping, save_best_model])\n",
        "pd.DataFrame(history.history).to_csv(\"Saved_Model/training_history.csv\")\n",
        "score = model.evaluate(test_x, test_y, verbose=1)\n",
        "print(score)\n",
        "model.save(\"Saved_Model/Model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqtbOK8o-oxQ",
        "outputId": "3fd1d026-a568-4ec0-ceca-8e73b3478efc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_14 (Conv2D)          (None, 64, 64, 64)        320       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 64, 64, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling2d_5 (Averag  (None, 32, 32, 64)       0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 16, 16, 128)       32896     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling2d_6 (Averag  (None, 8, 8, 128)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 4, 4, 256)         131328    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 4, 4, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling2d_7 (Averag  (None, 2, 2, 256)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 1, 1, 512)         524800    \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 1, 1, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling2d_8 (Averag  (None, 1, 1, 512)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 32)                0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 8)                 264       \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 863,848\n",
            "Trainable params: 860,904\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "315/316 [============================>.] - ETA: 0s - loss: 2.0546 - accuracy: 0.2505\n",
            "Epoch 00001: saving model to model_.01_2.65.hdf5\n",
            "316/316 [==============================] - 83s 255ms/step - loss: 2.0545 - accuracy: 0.2505 - val_loss: 2.6524 - val_accuracy: 0.1261\n",
            "Epoch 2/50\n",
            "315/316 [============================>.] - ETA: 0s - loss: 1.7888 - accuracy: 0.3328\n",
            "Epoch 00002: saving model to model_.02_2.15.hdf5\n",
            "316/316 [==============================] - 84s 265ms/step - loss: 1.7889 - accuracy: 0.3328 - val_loss: 2.1486 - val_accuracy: 0.1544\n",
            "Epoch 3/50\n",
            "315/316 [============================>.] - ETA: 0s - loss: 1.6946 - accuracy: 0.3796\n",
            "Epoch 00003: saving model to model_.03_2.46.hdf5\n",
            "316/316 [==============================] - 78s 247ms/step - loss: 1.6946 - accuracy: 0.3797 - val_loss: 2.4611 - val_accuracy: 0.2287\n",
            "Epoch 4/50\n",
            "315/316 [============================>.] - ETA: 0s - loss: 1.6294 - accuracy: 0.4109\n",
            "Epoch 00004: saving model to model_.04_2.60.hdf5\n",
            "316/316 [==============================] - 80s 252ms/step - loss: 1.6293 - accuracy: 0.4109 - val_loss: 2.5985 - val_accuracy: 0.2303\n",
            "Epoch 5/50\n",
            "315/316 [============================>.] - ETA: 0s - loss: 1.5839 - accuracy: 0.4330\n",
            "Epoch 00005: saving model to model_.05_2.67.hdf5\n",
            "316/316 [==============================] - 82s 260ms/step - loss: 1.5839 - accuracy: 0.4330 - val_loss: 2.6672 - val_accuracy: 0.1484\n",
            "Epoch 6/50\n",
            "225/316 [====================>.........] - ETA: 22s - loss: 1.5584 - accuracy: 0.4472"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-24e711d59577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m              metrics = ['accuracy'])\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if not os.path.exists('Saved_Model_4nd'):\n",
        "  os.mkdir('Saved_Model_4nd')\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=2, strides=2, activation='relu', input_shape=(128,128,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(pool_size=2, padding='same'))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=2, strides=2, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(pool_size=2, padding='same'))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=2, strides=2, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(pool_size=2, padding='same'))\n",
        "\n",
        "model.add(Conv2D(filters=512, kernel_size=2, strides=2, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(pool_size=2, padding='same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256))\n",
        "\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(8))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Save the model architecture\n",
        "plot_model(model, to_file=\"/content/Saved_Model_4nd/Model_Architecture.jpg\", show_shapes=True)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer = tf.keras.optimizers.RMSprop(),\n",
        "             metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(train_ds, epochs=50, verbose=1,  validation_data=val_ds, callbacks=[early_stopping, save_best_model])\n",
        "score = model.evaluate(test_ds, verbose=1)\n",
        "print(score)\n",
        "model.save(\"Saved_Model_4nd/Model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I am not using data augmentation"
      ],
      "metadata": {
        "id": "WCcDqa9kcBqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.batch(128).map(lambda x, y: (normalization_layer(x), y))"
      ],
      "metadata": {
        "id": "1n2LLlNBY8Aj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KREEBDyyal5Q",
        "outputId": "b0a6ab18-09c3-4103-97b9-a217377833b0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: ((None, 128, 128, 1), (None, 8)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9phCPSX09XGG",
        "outputId": "16b11f10-5a1f-41af-b2e8-5830cc938275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 122, 122, 64)      3200      \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 122, 122, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling2d_4 (Averag  (None, 61, 61, 64)       0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 28, 28, 128)       401536    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 28, 28, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling2d_5 (Averag  (None, 14, 14, 128)      0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 12, 12, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling2d_6 (Averag  (None, 6, 6, 256)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 4, 4, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling2d_7 (Averag  (None, 2, 2, 512)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 2, 2, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 2048)             8192      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 8)                 264       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,273,512\n",
            "Trainable params: 4,266,472\n",
            "Non-trainable params: 7,040\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "316/316 [==============================] - 99s 270ms/step - loss: 2.2103 - accuracy: 0.2778 - val_loss: 2.8244 - val_accuracy: 0.1542\n",
            "Epoch 2/50\n",
            "316/316 [==============================] - 85s 269ms/step - loss: 1.8353 - accuracy: 0.3586 - val_loss: 2.0488 - val_accuracy: 0.2776\n",
            "Epoch 3/50\n",
            "316/316 [==============================] - 87s 276ms/step - loss: 1.7181 - accuracy: 0.4008 - val_loss: 1.8221 - val_accuracy: 0.3264\n",
            "Epoch 4/50\n",
            "316/316 [==============================] - 86s 272ms/step - loss: 1.6300 - accuracy: 0.4385 - val_loss: 1.9188 - val_accuracy: 0.3858\n",
            "Epoch 5/50\n",
            "316/316 [==============================] - 86s 271ms/step - loss: 1.5682 - accuracy: 0.4630 - val_loss: 1.8183 - val_accuracy: 0.3543\n",
            "Epoch 6/50\n",
            "316/316 [==============================] - 87s 274ms/step - loss: 1.5050 - accuracy: 0.4896 - val_loss: 1.7118 - val_accuracy: 0.3938\n",
            "Epoch 7/50\n",
            "316/316 [==============================] - 85s 268ms/step - loss: 1.4592 - accuracy: 0.5072 - val_loss: 1.6182 - val_accuracy: 0.4652\n",
            "Epoch 8/50\n",
            "316/316 [==============================] - 85s 267ms/step - loss: 1.4175 - accuracy: 0.5244 - val_loss: 1.6179 - val_accuracy: 0.4712\n",
            "Epoch 9/50\n",
            "316/316 [==============================] - 85s 270ms/step - loss: 1.3753 - accuracy: 0.5386 - val_loss: 1.9049 - val_accuracy: 0.3889\n",
            "Epoch 10/50\n",
            "316/316 [==============================] - 85s 268ms/step - loss: 1.3532 - accuracy: 0.5466 - val_loss: 1.9081 - val_accuracy: 0.3559\n",
            "Epoch 11/50\n",
            "316/316 [==============================] - 86s 273ms/step - loss: 1.3078 - accuracy: 0.5634 - val_loss: 1.5279 - val_accuracy: 0.4911\n",
            "Epoch 12/50\n",
            "316/316 [==============================] - 89s 281ms/step - loss: 1.2790 - accuracy: 0.5745 - val_loss: 1.6499 - val_accuracy: 0.4643\n",
            "Epoch 13/50\n",
            "316/316 [==============================] - 85s 269ms/step - loss: 1.2493 - accuracy: 0.5845 - val_loss: 1.4132 - val_accuracy: 0.5167\n",
            "Epoch 14/50\n",
            "316/316 [==============================] - 85s 268ms/step - loss: 1.2202 - accuracy: 0.5967 - val_loss: 1.2900 - val_accuracy: 0.5765\n",
            "Epoch 15/50\n",
            "316/316 [==============================] - 85s 268ms/step - loss: 1.1856 - accuracy: 0.6079 - val_loss: 1.9323 - val_accuracy: 0.4480\n",
            "Epoch 16/50\n",
            "316/316 [==============================] - 85s 269ms/step - loss: 1.1519 - accuracy: 0.6202 - val_loss: 1.4601 - val_accuracy: 0.5415\n",
            "Epoch 17/50\n",
            "316/316 [==============================] - 87s 274ms/step - loss: 1.1389 - accuracy: 0.6240 - val_loss: 1.3060 - val_accuracy: 0.5701\n",
            "Epoch 18/50\n",
            "316/316 [==============================] - 86s 271ms/step - loss: 1.0936 - accuracy: 0.6399 - val_loss: 1.3379 - val_accuracy: 0.5618\n",
            "Epoch 19/50\n",
            "316/316 [==============================] - 85s 269ms/step - loss: 1.0586 - accuracy: 0.6538 - val_loss: 1.4413 - val_accuracy: 0.5303\n",
            "Epoch 20/50\n",
            "316/316 [==============================] - 85s 268ms/step - loss: 1.0270 - accuracy: 0.6630 - val_loss: 1.3796 - val_accuracy: 0.5484\n",
            "Epoch 21/50\n",
            "316/316 [==============================] - 84s 266ms/step - loss: 0.9874 - accuracy: 0.6797 - val_loss: 1.6588 - val_accuracy: 0.4904\n",
            "Epoch 22/50\n",
            "316/316 [==============================] - 84s 266ms/step - loss: 0.9618 - accuracy: 0.6895 - val_loss: 1.4232 - val_accuracy: 0.5685\n",
            "Epoch 23/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.9477 - accuracy: 0.6939 - val_loss: 1.2597 - val_accuracy: 0.6274\n",
            "Epoch 24/50\n",
            "316/316 [==============================] - 85s 267ms/step - loss: 0.8920 - accuracy: 0.7146 - val_loss: 1.6520 - val_accuracy: 0.5397\n",
            "Epoch 25/50\n",
            "316/316 [==============================] - 85s 267ms/step - loss: 0.8567 - accuracy: 0.7287 - val_loss: 1.5589 - val_accuracy: 0.5656\n",
            "Epoch 26/50\n",
            "316/316 [==============================] - 85s 269ms/step - loss: 0.8270 - accuracy: 0.7368 - val_loss: 1.3720 - val_accuracy: 0.5944\n",
            "Epoch 27/50\n",
            "316/316 [==============================] - 85s 269ms/step - loss: 0.7828 - accuracy: 0.7543 - val_loss: 1.2042 - val_accuracy: 0.6464\n",
            "Epoch 28/50\n",
            "316/316 [==============================] - 85s 267ms/step - loss: 0.7452 - accuracy: 0.7663 - val_loss: 1.8019 - val_accuracy: 0.5203\n",
            "Epoch 29/50\n",
            "316/316 [==============================] - 85s 268ms/step - loss: 0.7240 - accuracy: 0.7737 - val_loss: 1.3702 - val_accuracy: 0.5995\n",
            "Epoch 30/50\n",
            "316/316 [==============================] - 85s 269ms/step - loss: 0.6769 - accuracy: 0.7901 - val_loss: 1.5169 - val_accuracy: 0.5805\n",
            "Epoch 31/50\n",
            "316/316 [==============================] - 85s 267ms/step - loss: 0.6388 - accuracy: 0.8041 - val_loss: 1.4046 - val_accuracy: 0.5817\n",
            "Epoch 32/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.6104 - accuracy: 0.8146 - val_loss: 1.6736 - val_accuracy: 0.5745\n",
            "Epoch 33/50\n",
            "316/316 [==============================] - 85s 268ms/step - loss: 0.5913 - accuracy: 0.8182 - val_loss: 1.5728 - val_accuracy: 0.6011\n",
            "Epoch 34/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.5621 - accuracy: 0.8311 - val_loss: 1.6322 - val_accuracy: 0.5823\n",
            "Epoch 35/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.5262 - accuracy: 0.8427 - val_loss: 1.9986 - val_accuracy: 0.5754\n",
            "Epoch 36/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.5047 - accuracy: 0.8507 - val_loss: 1.4593 - val_accuracy: 0.6468\n",
            "Epoch 37/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.4785 - accuracy: 0.8607 - val_loss: 1.8613 - val_accuracy: 0.5817\n",
            "Epoch 38/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.4698 - accuracy: 0.8636 - val_loss: 1.7656 - val_accuracy: 0.5939\n",
            "Epoch 39/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.4485 - accuracy: 0.8688 - val_loss: 2.1358 - val_accuracy: 0.5498\n",
            "Epoch 40/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.4208 - accuracy: 0.8787 - val_loss: 2.0687 - val_accuracy: 0.5564\n",
            "Epoch 41/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.3905 - accuracy: 0.8919 - val_loss: 2.6951 - val_accuracy: 0.5105\n",
            "Epoch 42/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.3833 - accuracy: 0.8937 - val_loss: 1.8967 - val_accuracy: 0.5799\n",
            "Epoch 43/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.3638 - accuracy: 0.8985 - val_loss: 2.0333 - val_accuracy: 0.5837\n",
            "Epoch 44/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.3615 - accuracy: 0.9006 - val_loss: 1.8211 - val_accuracy: 0.6091\n",
            "Epoch 45/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.4172 - accuracy: 0.8830 - val_loss: 2.5110 - val_accuracy: 0.4877\n",
            "Epoch 46/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.3564 - accuracy: 0.9020 - val_loss: 1.6256 - val_accuracy: 0.6348\n",
            "Epoch 47/50\n",
            "316/316 [==============================] - 85s 268ms/step - loss: 0.3110 - accuracy: 0.9197 - val_loss: 1.6248 - val_accuracy: 0.6194\n",
            "Epoch 48/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.3072 - accuracy: 0.9200 - val_loss: 1.5838 - val_accuracy: 0.6582\n",
            "Epoch 49/50\n",
            "316/316 [==============================] - 84s 266ms/step - loss: 0.2781 - accuracy: 0.9304 - val_loss: 1.8935 - val_accuracy: 0.6082\n",
            "Epoch 50/50\n",
            "316/316 [==============================] - 84s 267ms/step - loss: 0.2887 - accuracy: 0.9271 - val_loss: 1.5381 - val_accuracy: 0.6642\n",
            "39/39 [==============================] - 6s 144ms/step - loss: 1.5271 - accuracy: 0.6753\n",
            "[1.5271384716033936, 0.675301194190979]\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists('/content/gdrive/MyDrive/Saved_Model_Batch'):\n",
        "  os.mkdir('/content/gdrive/MyDrive/Saved_Model_Batch')\n",
        "\n",
        "\n",
        "# HERE WE TRY TO IMPROVE THE PREVIOUS RESULT BY ADDING A BATCH NORMALIZATION LAYER AFTER\n",
        "# EACH CONVOLUTIONAL LAYER\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=64, kernel_size=[7,7], activation=\"relu\", kernel_regularizer=regularizers.l2(0.0001), input_shape=(128,128,1)))\n",
        "# Dim = (122x122x64)\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(pool_size=[2,2], strides=2))\n",
        "# Dim = (61x61x64)\n",
        "model.add(Conv2D(filters=128, kernel_size=[7,7], strides=2, kernel_regularizer=regularizers.l2(0.0001), activation=\"relu\"))\n",
        "# Dim = (28x28x128)\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(pool_size=[2,2], strides=2))\n",
        "# Dim = (14x14x128)\n",
        "model.add(Conv2D(filters=256, kernel_size=[3,3], kernel_regularizer=regularizers.l2(0.0001), activation=\"relu\"))\n",
        "# Dim = (12x12x256)\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(pool_size=[2,2], strides=2))\n",
        "# Dim = (6x6x256)\n",
        "model.add(Conv2D(filters=512, kernel_size=[3,3], kernel_regularizer=regularizers.l2(0.0001), activation=\"relu\"))\n",
        "# Dim = (4x4x512)\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(pool_size=[2,2], strides=2))\n",
        "# Dim = (2x2x512)\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "# Dim = (2048)\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(1024, activation=\"elu\"))\n",
        "# Dim = (1024)\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation=\"elu\"))\n",
        "# Dim = (256)\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(64, activation=\"elu\"))\n",
        "# Dim = (64)\n",
        "model.add(Dense(32, activation=\"elu\"))\n",
        "# Dim = (32)\n",
        "model.add(Dense(8, activation=\"softmax\"))\n",
        "# Dim = (8)\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "# compile\n",
        "model.compile(loss=\"categorical_crossentropy\", \n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Save the training history\n",
        "history = model.fit(train_ds, epochs=50, verbose=1,  validation_data=val_ds)\n",
        "#pd.DataFrame(model.fit(train_x, train_y, batch_size=64, epochs=5, verbose=1, validation_split=0.1).history).to_csv(\"/content/gdrive/MyDrive/Saved_Model_Batch/training_history.csv\")\n",
        "\n",
        "# evaluate on the test set\n",
        "score = model.evaluate(test_ds, verbose=1)\n",
        "print(score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the training history\n",
        "pd.DataFrame(history.history).to_csv('/content/gdrive/MyDrive/Saved_Model_Batch/my_model_50.csv')"
      ],
      "metadata": {
        "id": "iyajzKJJp3aV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the learning curves\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "VzOPtAJ2qMKd",
        "outputId": "1ad2b7a6-954f-4ad9-89fd-72b656b0d173"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "XHH8WlpO1sVn",
        "outputId": "c2f29116-d795-49d7-c2c0-bba7138fdf77"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "model.save('/content/gdrive/MyDrive/Saved_Model_Batch/Model.h5')"
      ],
      "metadata": {
        "id": "R5p9k2uGb86I"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can try to improve the performance by performing data augmentation"
      ],
      "metadata": {
        "id": "Ow0ZfKjGc2QI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_aug = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "lmx-8FQIdZl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# augment the training dataset\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.Rescaling(1./255),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomTranslation(height_factor=0.2, width_factor=0.2, fill_mode=\"nearest\")\n",
        "    ])\n",
        "\n",
        "train_ds_aug = train_ds_aug.batch(128).map(lambda x, y: (data_augmentation(x), y))\n"
      ],
      "metadata": {
        "id": "dsXRJB7T1pGL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimensions\n",
        "train_ds_aug"
      ],
      "metadata": {
        "id": "Vv2xYL3KkfUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/gdrive/MyDrive/Saved_Model_Aug'):\n",
        "  os.mkdir('/content/gdrive/MyDrive/Saved_Model_Aug')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "save_best_model = ModelCheckpoint(filepath='model_.{epoch:02d}_{val_loss:.2f}.hdf5', verbose=1,\n",
        "        monitor='val_loss', save_best_only=True,)\n",
        "\n",
        "# HERE WE TRY TO IMPROVE THE PREVIOUS RESULT BY ADDING A BATCH NORMALIZATION LAYER AFTER\n",
        "# EACH CONVOLUTIONAL LAYER\n",
        "\n",
        "\n",
        "model_aug = Sequential()\n",
        "model_aug.add(Conv2D(filters=64, kernel_size=[7,7], activation=\"relu\", kernel_regularizer=regularizers.l2(0.0001), input_shape=(128,128,1)))\n",
        "# Dim = (122x122x64)\n",
        "model_aug.add(BatchNormalization())\n",
        "model_aug.add(AveragePooling2D(pool_size=[2,2], strides=2))\n",
        "# Dim = (61x61x64)\n",
        "model_aug.add(Conv2D(filters=128, kernel_size=[7,7], strides=2, kernel_regularizer=regularizers.l2(0.0001), activation=\"relu\"))\n",
        "# Dim = (28x28x128)\n",
        "model_aug.add(BatchNormalization())\n",
        "model_aug.add(AveragePooling2D(pool_size=[2,2], strides=2))\n",
        "# Dim = (14x14x128)\n",
        "model_aug.add(Conv2D(filters=256, kernel_size=[3,3], kernel_regularizer=regularizers.l2(0.0001), activation=\"relu\"))\n",
        "# Dim = (12x12x256)\n",
        "model_aug.add(BatchNormalization())\n",
        "model_aug.add(AveragePooling2D(pool_size=[2,2], strides=2))\n",
        "# Dim = (6x6x256)\n",
        "model_aug.add(Conv2D(filters=512, kernel_size=[3,3], kernel_regularizer=regularizers.l2(0.0001), activation=\"relu\"))\n",
        "# Dim = (4x4x512)\n",
        "model_aug.add(BatchNormalization())\n",
        "model_aug.add(AveragePooling2D(pool_size=[2,2], strides=2))\n",
        "# Dim = (2x2x512)\n",
        "model_aug.add(BatchNormalization())\n",
        "model_aug.add(Flatten())\n",
        "# Dim = (2048)\n",
        "model_aug.add(BatchNormalization())\n",
        "model_aug.add(Dropout(0.6))\n",
        "model_aug.add(Dense(1024, activation=\"elu\"))\n",
        "# Dim = (1024)\n",
        "model_aug.add(Dropout(0.5))\n",
        "model_aug.add(Dense(256, activation=\"elu\"))\n",
        "# Dim = (256)\n",
        "model_aug.add(Dropout(0.25))\n",
        "model_aug.add(Dense(64, activation=\"elu\"))\n",
        "# Dim = (64)\n",
        "model_aug.add(Dense(32, activation=\"elu\"))\n",
        "# Dim = (32)\n",
        "model_aug.add(Dense(8, activation=\"softmax\"))\n",
        "# Dim = (8)\n",
        "print(model_aug.summary())\n",
        "\n",
        "\n",
        "# compile\n",
        "model_aug.compile(loss=\"categorical_crossentropy\", \n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Save the training history\n",
        "history_aug = model_aug.fit(train_ds_aug, epochs=50, verbose=1,  validation_data=val_ds, callbacks=[early_stopping, save_best_model])\n",
        "#pd.DataFrame(model.fit(train_x, train_y, batch_size=64, epochs=5, verbose=1, validation_split=0.1).history).to_csv(\"/content/gdrive/MyDrive/Saved_Model_Batch/training_history.csv\")\n",
        "\n",
        "# evaluate on the test set\n",
        "score_aug = model_aug.evaluate(test_ds, verbose=1)\n",
        "print(score_aug)\n"
      ],
      "metadata": {
        "id": "9R8qFlhTggy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the training history\n",
        "pd.DataFrame(history_aug.history).to_csv('/content/gdrive/MyDrive/Saved_Model_Aug/my_model_50.csv')"
      ],
      "metadata": {
        "id": "0LmGW6eWhBhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "model_aug.save('/content/gdrive/MyDrive/Saved_Model_Batch/Model.h5')"
      ],
      "metadata": {
        "id": "hp1J_TxOj4ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to improve the performance, we will try to use a pretrained network VGG, which will use colored images."
      ],
      "metadata": {
        "id": "Gaxwg0EO6Pe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_1 = train_x_1.reshape(train_x_1.shape[0], train_x_1.shape[1], train_x_1.shape[2], 3)"
      ],
      "metadata": {
        "id": "qM5WuFW6lNEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model = tf.keras.applications.vgg16.VGG16(weights='imagenet',include_top=False, input_shape=(128, 128, 3))"
      ],
      "metadata": {
        "id": "HVziYKPBqsYw",
        "outputId": "ff3051fe-097f-4ec4-91d0-45c982734f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-c7ef7e9719b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvgg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    132\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m       \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m       weights=weights)\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    370\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`input_shape` must be a tuple of three integers.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m           raise ValueError('The input must have 3 channels; Received '\n\u001b[0m\u001b[1;32m    373\u001b[0m                            f'`input_shape={input_shape}`')\n\u001b[1;32m    374\u001b[0m         if ((input_shape[0] is not None and input_shape[0] < min_size) or\n",
            "\u001b[0;31mValueError\u001b[0m: The input must have 3 channels; Received `input_shape=(128, 128, 1)`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg_model.layers:\n",
        "layer.trainable = False\n",
        "# Make sure you have frozen the correct layers\n",
        "for i, layer in enumerate(vgg_model.layers):\n",
        "    print(i, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "gucLZccHnK5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_vgg = Sequential()\n",
        "\n",
        "vgg_model\n",
        "model_vgg.add(Flatten())\n",
        "# Dim = (2048)\n",
        "model_vgg.add(BatchNormalization())\n",
        "model_vgg.add(Dropout(0.6))\n",
        "model_vgg.add(Dense(1024, activation=\"elu\"))\n",
        "# Dim = (1024)\n",
        "model_vgg.add(Dropout(0.5))\n",
        "model_vgg.add(Dense(256, activation=\"elu\"))\n",
        "# Dim = (256)\n",
        "model_vgg.add(Dropout(0.25))\n",
        "model_vgg.add(Dense(64, activation=\"elu\"))\n",
        "# Dim = (64)\n",
        "model_vgg.add(Dense(32, activation=\"elu\"))\n",
        "# Dim = (32)\n",
        "model_vgg.add(Dense(8, activation=\"softmax\"))\n",
        "# Dim = (8)\n",
        "print(model_vgg.summary())\n",
        "\n",
        "\n",
        "# compile\n",
        "model_vgg.compile(loss=\"categorical_crossentropy\", \n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Save the training history\n",
        "history_vgg = model_vgg.fit(train_ds, epochs=50, verbose=1,  validation_data=val_ds)\n",
        "#pd.DataFrame(model.fit(train_x, train_y, batch_size=64, epochs=5, verbose=1, validation_split=0.1).history).to_csv(\"/content/gdrive/MyDrive/Saved_Model_Batch/training_history.csv\")\n",
        "\n",
        "# evaluate on the test set\n",
        "score_vgg = model_vgg.evaluate(test_ds, verbose=1)\n",
        "print(score_vgg)"
      ],
      "metadata": {
        "id": "QzJj31x-nP4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKIXkn5P-hiX"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model, load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaZNnCqv-JGW"
      },
      "outputs": [],
      "source": [
        "# Load the trained model.\n",
        "loaded_model = load_model(\"/content/gdrive/MyDrive/Saved_Model_Batch/Model.h5\")\n",
        "loaded_model.set_weights(loaded_model.get_weights())\n",
        "# Discard the Softmax layer, Second last layer provides the latent feature\n",
        "# representation.\n",
        "matrix_size = loaded_model.layers[-2].output.shape[1]\n",
        "new_model = Model(loaded_model.inputs, loaded_model.layers[-2].output)\n",
        "print(new_model.summary())\n",
        "\n",
        "images, labels = load_dataset(verbose=1, mode=\"Test\")\n",
        "images = np.expand_dims(images, axis=3)\n",
        "# Normalize the image.\n",
        "images = images / 255.\n",
        "# Display list of available test songs.\n",
        "print(np.unique(labels))\n",
        "# Enter a song name which will be an anchor song.\n",
        "recommend_wrt = input(\"Enter Song name:\\n\")\n",
        "prediction_anchor = np.zeros((1, matrix_size))\n",
        "count = 0\n",
        "predictions_song = []\n",
        "predictions_label = []\n",
        "counts = []\n",
        "distance_array = []\n",
        "\n",
        "# Calculate the latent feature vectors for all the songs.\n",
        "for i in range(0, len(labels)):\n",
        "    if(labels[i] == recommend_wrt):\n",
        "        test_image = images[i]\n",
        "        test_image = np.expand_dims(test_image, axis=0)\n",
        "        prediction = new_model.predict(test_image)\n",
        "        prediction_anchor = prediction_anchor + prediction\n",
        "        count = count + 1\n",
        "    elif(labels[i] not in predictions_label):\n",
        "        predictions_label.append(labels[i])\n",
        "        test_image = images[i]\n",
        "        test_image = np.expand_dims(test_image, axis=0)\n",
        "        prediction = new_model.predict(test_image)\n",
        "        predictions_song.append(prediction)\n",
        "        counts.append(1)\n",
        "    elif(labels[i] in predictions_label):\n",
        "        index = predictions_label.index(labels[i])\n",
        "        test_image = images[i]\n",
        "        test_image = np.expand_dims(test_image, axis=0)\n",
        "        prediction = new_model.predict(test_image)\n",
        "        predictions_song[index] = predictions_song[index] + prediction\n",
        "        counts[index] = counts[index] + 1\n",
        "# Count is used for averaging the latent feature vectors.\n",
        "prediction_anchor = prediction_anchor / count\n",
        "for i in range(len(predictions_song)):\n",
        "    predictions_song[i] = predictions_song[i] / counts[i]\n",
        "    # Cosine Similarity - Computes a similarity score of all songs with respect\n",
        "    # to the anchor song.\n",
        "    distance_array.append(np.sum(prediction_anchor * predictions_song[i]) / (np.sqrt(np.sum(prediction_anchor**2)) * np.sqrt(np.sum(predictions_song[i]**2))))\n",
        "\n",
        "distance_array = np.array(distance_array)\n",
        "recommendations = 0\n",
        "\n",
        "print(\"Recommendation is:\")\n",
        "\n",
        "# Number of Recommendations is set to 2.\n",
        "while recommendations < 2:\n",
        "    index = np.argmax(distance_array)\n",
        "    value = distance_array[index]\n",
        "    print(\"Song Name: \" + predictions_label[index] + \" with value = %f\" % (value))\n",
        "    distance_array[index] = -np.inf\n",
        "    recommendations = recommendations + 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "copia.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgsvpnlb6amPUWKtrPtL9T",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}